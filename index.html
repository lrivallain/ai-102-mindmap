<!DOCTYPE html>
<html>
<head>
<link rel="icon" type="image/png" href="favicon.png">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>{{ env.MAP_TITLE }}</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@highlightjs/cdn-assets@11.8.0/styles/default.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.17.0/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.17.0/dist/browser/index.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.17.0/dist/index.js"></script><script>((r) => {
            setTimeout(r);
          })(() => {
  const { markmap, mm } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute("style", "position:absolute;bottom:20px;right:20px");
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root2, jsonOptions) => {
              const markmap = getMarkmap();
              window.mm = markmap.Markmap.create(
                "svg#mindmap",
                (getOptions || markmap.deriveOptions)(jsonOptions),
                root2
              );
            })(() => window.markmap,null,{"content":"AI-102: Azure AI Engineer Associate","children":[{"content":"AI-102 - Resources","children":[{"content":"<a href=\"https://learn.microsoft.com/en-us/certifications/exams/ai-102\">AI-102: Azure AI Engineer Associate</a>","children":[],"payload":{"lines":"2,3"}},{"content":"Course: <a href=\"https://learn.microsoft.com/en-us/training/courses/ai-102t00/\">Designing and Implementing a Microsoft Azure AI Solution</a>","children":[],"payload":{"lines":"3,4"}},{"content":"<a href=\"https://learn.microsoft.com/en-us/credentials/certifications/resources/study-guides/ai-102\">Study guide</a>","children":[],"payload":{"lines":"4,5"}},{"content":"<a href=\"https://learn.microsoft.com/en-us/credentials/certifications/azure-ai-engineer/practice/assessment?assessment-type=practice&amp;assessmentId=61&amp;practice-assessment-type=certification\">Practice assessment</a>","children":[],"payload":{"lines":"5,6"}},{"content":"<a href=\"https://learn.microsoft.com/en-us/shows/exam-readiness-zone/preparing-for-ai-102-plan-and-manage-an-azure-ai-solution\">Exam prep videos</a>","children":[],"payload":{"lines":"6,7"}},{"content":"Azure <a href=\"https://azure.github.io/aihub\">AI Hub</a>","children":[],"payload":{"lines":"7,8"}},{"content":"<a href=\"https://aka.ms/examdemo\">Exam Sandbox</a>: Experience the look and feel of the exam interface before taking it.","children":[],"payload":{"lines":"8,10"}}],"payload":{"lines":"0,1","fold":1}},{"content":"Skills at a glance","children":[{"content":"Plan and manage an Azure AI solution (15–20%)","children":[{"content":"Select the appropriate Azure AI service","children":[{"content":"List of Azure AI Services","children":[{"content":"<img src=\"./static/images/List_of_AzureAIServices.png\" alt=\"List of Azure AI Services\">","children":[],"payload":{"lines":"18,20"}}],"payload":{"lines":"16,17"}},{"content":"Select the appropriate service for a computer vision solution","children":[{"content":"Azure AI Vision","children":[{"content":"Processes images and videos to understand their content","children":[],"payload":{"lines":"24,26"}}],"payload":{"lines":"22,23"}},{"content":"Face API","children":[{"content":"Detects and recognizes human faces","children":[],"payload":{"lines":"28,30"}}],"payload":{"lines":"26,27"}},{"content":"Azure AI Custom Vision Service","children":[{"content":"Builds and deploys custom image classification models","children":[],"payload":{"lines":"32,34"}}],"payload":{"lines":"30,31"}},{"content":"Document Intelligence","children":[{"content":"Extracts text, key-value pairs, and tables from documents","children":[],"payload":{"lines":"36,38"}}],"payload":{"lines":"34,35"}},{"content":"Azure AI Video Indexer","children":[{"content":"Extracts insights from videos and live streams","children":[],"payload":{"lines":"40,42"}}],"payload":{"lines":"38,39"}}],"payload":{"lines":"20,21"}},{"content":"Select the appropriate service for a natural language processing solution","children":[{"content":"Custom text classification","children":[],"payload":{"lines":"44,45"}},{"content":"Custom named entity recognition","children":[],"payload":{"lines":"45,46"}},{"content":"Conversational Language Understanding","children":[],"payload":{"lines":"46,47"}},{"content":"Entity Linking","children":[],"payload":{"lines":"47,48"}},{"content":"Key Phrase Extraction","children":[],"payload":{"lines":"48,49"}},{"content":"Language Detection","children":[],"payload":{"lines":"49,50"}},{"content":"Named Entity Recognition (NER)","children":[],"payload":{"lines":"50,51"}},{"content":"Orchestration workflow","children":[],"payload":{"lines":"51,52"}},{"content":"Personally identifiable information (PII) detection","children":[],"payload":{"lines":"52,53"}},{"content":"Question Answering","children":[],"payload":{"lines":"53,54"}},{"content":"Sentiment Analysis","children":[],"payload":{"lines":"54,55"}},{"content":"Summarization","children":[],"payload":{"lines":"55,56"}},{"content":"Text Analytics for Health","children":[],"payload":{"lines":"56,58"}}],"payload":{"lines":"42,43"}},{"content":"Select the appropriate service for a speech solution","children":[{"content":"Speech to Text","children":[{"content":"Supports intermediate results, end-of-speech detection, automatic text formatting, profanity<br>\nmasking, and includes real-time speech-to-text and batch transcription","children":[],"payload":{"lines":"62,65"}}],"payload":{"lines":"60,61"}},{"content":"Language identification","children":[{"content":"Identifies the spoken language in a given audio stream","children":[],"payload":{"lines":"67,69"}}],"payload":{"lines":"65,66"}},{"content":"Text-to-Speech","children":[{"content":"Converts text to natural-sounding speech","children":[],"payload":{"lines":"71,73"}}],"payload":{"lines":"69,70"}},{"content":"Speech Recognition","children":[{"content":"Identifies and verifies the people speaking based on audio","children":[],"payload":{"lines":"75,77"}}],"payload":{"lines":"73,74"}},{"content":"Pronunciation Assessment","children":[{"content":"Evaluates the pronunciation and provides feedback on the accuracy and fluency of the<br>\nspeech","children":[],"payload":{"lines":"79,82"}}],"payload":{"lines":"77,78"}},{"content":"Speech translation","children":[{"content":"Translates streaming audio in real-time and provides result as text/synthesized speech","children":[],"payload":{"lines":"84,86"}}],"payload":{"lines":"82,83"}},{"content":"Intent recognition","children":[{"content":"Derives user intents from transcribed speech and act on voice commands","children":[],"payload":{"lines":"88,90"}}],"payload":{"lines":"86,87"}}],"payload":{"lines":"58,59"}},{"content":"Select the appropriate service for a generative AI solution","children":[{"content":"Build your own copilot and generative AI applications with:","children":[{"content":"Azure OpenAI Service","children":[],"payload":{"lines":"93,94"}},{"content":"Azure AI Studio","children":[{"content":"Provides a low-code/no-code environment for building AI tools based on various AI models:","children":[{"content":"Open AI (DALL-E, GPT, Wisper...)","children":[],"payload":{"lines":"96,97"}},{"content":"Mistral AI","children":[],"payload":{"lines":"97,98"}},{"content":"Meta (Llama)","children":[],"payload":{"lines":"98,99"}},{"content":"Cohere (Command R, Rerank...)","children":[],"payload":{"lines":"99,101"}}],"payload":{"lines":"95,101"}}],"payload":{"lines":"94,101"}}],"payload":{"lines":"92,101"}}],"payload":{"lines":"90,91"}},{"content":"Select the appropriate service for a document intelligence solution","children":[{"content":"Azure AI Document Intelligence:","children":[{"content":"Document analysis model","children":[],"payload":{"lines":"104,105"}},{"content":"Prebuilt model","children":[],"payload":{"lines":"105,106"}},{"content":"Custom model","children":[],"payload":{"lines":"106,108"}}],"payload":{"lines":"103,108"}}],"payload":{"lines":"101,102"}},{"content":"Select the appropriate service for a knowledge mining solution","children":[{"content":"Azure AI Search","children":[],"payload":{"lines":"110,112"}}],"payload":{"lines":"108,109"}}],"payload":{"lines":"14,15"}},{"content":"Plan, create and deploy an Azure AI service","children":[{"content":"Plan for a solution that meets Responsible AI principles","children":[{"content":"<strong>Fairness</strong>: AI systems should treat all people fairly.","children":[{"content":"<strong>Fairlearn</strong>: An Open-source toolkit for assessing and improving the<br>\nfairness of machine learning models.","children":[],"payload":{"lines":"117,119"}}],"payload":{"lines":"116,119"}},{"content":"<strong>Reliability and safety</strong>: AI systems should perform reliably and safely.","children":[{"content":"Test the model","children":[],"payload":{"lines":"120,121"}},{"content":"Risks and harm related information should be accessible from the model users","children":[],"payload":{"lines":"121,122"}}],"payload":{"lines":"119,122"}},{"content":"<strong>Privacy and security</strong>: AI systems should respect privacy and maintain security.","children":[{"content":"Personally identifiable information (PII) should be protected","children":[],"payload":{"lines":"123,124"}}],"payload":{"lines":"122,124"}},{"content":"<strong>Inclusiveness</strong>: AI systems should empower everyone and engage people.","children":[],"payload":{"lines":"124,125"}},{"content":"<strong>Transparency</strong>: AI systems should be transparent and understandable.","children":[{"content":"<em>Interpretability/Intellegibility</em>: The ability to explain the results of a model<br>\nin a way that is understandable to humans.","children":[],"payload":{"lines":"126,128"}}],"payload":{"lines":"125,128"}},{"content":"<strong>Accountability</strong>: AI systems should be accountable to people.","children":[{"content":"<strong>Model governance</strong>: The process of managing the entire lifecycle of a model,<br>\nincluding model creation, deployment, and monitoring.","children":[],"payload":{"lines":"129,131"}},{"content":"<strong>Organizational principles</strong>: Define the roles and responsibilities of the<br>\npeople involved in the model lifecycle.","children":[],"payload":{"lines":"131,134"}}],"payload":{"lines":"128,134"}}],"payload":{"lines":"114,115"}},{"content":"Create an Azure AI resource","children":[{"content":"From the Azure portal","children":[],"payload":{"lines":"136,137"}},{"content":"Using Azure CLI","children":[],"payload":{"lines":"137,138"}},{"content":"Using client librariy","children":[],"payload":{"lines":"138,139"}},{"content":"Using ARM templates, Bicep, or Terraform","children":[],"payload":{"lines":"139,141"}}],"payload":{"lines":"134,135"}},{"content":"Determine a default endpoint for a service","children":[{"content":"Multi-service resource","children":[{"content":"Multiple Azure AI resources with a single key and endpoint","children":[],"payload":{"lines":"144,145"}},{"content":"Consolidate billing from the the services you use","children":[],"payload":{"lines":"145,146"}}],"payload":{"lines":"143,146"}},{"content":"Single-service resource","children":[{"content":"Single Azure AI resource with a single key and endpoint","children":[],"payload":{"lines":"147,148"}},{"content":"Use free tier for testing and development: only supported in single-service resources","children":[],"payload":{"lines":"148,149"}}],"payload":{"lines":"146,149"}},{"content":"Endpoint URI is one of the three primary parameters for Azure AI","children":[],"payload":{"lines":"149,150"}},{"content":"2 (access) keys are provided for each Azure AI resource by default","children":[{"content":"Protect the keys by using Azure Key Vault","children":[],"payload":{"lines":"151,152"}}],"payload":{"lines":"150,152"}},{"content":"Authenticate with:","children":[{"content":"Single or multi-service key","children":[],"payload":{"lines":"153,154"}},{"content":"Token (REST API)","children":[],"payload":{"lines":"154,155"}},{"content":"Entra ID identity","children":[],"payload":{"lines":"155,157"}}],"payload":{"lines":"152,157"}}],"payload":{"lines":"141,142"}},{"content":"Integrate Azure AI services into a continuous integration and continuous delivery (CI/CD) pipeline","children":[],"payload":{"lines":"157,158"}},{"content":"Plan and implement a container deployment","children":[{"content":"<mark>Azure Container Instances</mark> (ACI): on demand standalones containers with minimal setup in<br>\nserverless environment.","children":[],"payload":{"lines":"161,163"}},{"content":"<mark>Azure Kubernetes Service</mark> (AKS): Managed Kubernetes service for deploying, managing, and<br>\nscaling containerized applications using Kubernetes.","children":[],"payload":{"lines":"163,166"}}],"payload":{"lines":"159,160"}}],"payload":{"lines":"112,113"}},{"content":"Manage, monitor, and secure an Azure AI service","children":[{"content":"Configure diagnostic logging","children":[{"content":"Enable diagnostic logging for an Azure AI resource:","children":[{"content":"<mark>Log Analytics Workspace</mark> to analyze logs and metrics (Azure Monitor)","children":[],"payload":{"lines":"171,172"}},{"content":"<mark>Event Hub</mark> for streaming logs to other services","children":[],"payload":{"lines":"172,173"}},{"content":"<mark>Storage Account</mark> for archiving logs with less expensive storage","children":[],"payload":{"lines":"173,175"}}],"payload":{"lines":"170,175"}}],"payload":{"lines":"168,169"}},{"content":"Monitor an Azure AI resource","children":[{"content":"<em>Metrics</em>: capture regular data points about the behavior of the resource in time-series database","children":[],"payload":{"lines":"177,178"}},{"content":"<em>Alerts</em>: notify you when a metric breaches a threshold","children":[],"payload":{"lines":"178,179"}},{"content":"<em>Diagnostics settings</em>: configure the resource to send logs and metrics to a destination","children":[],"payload":{"lines":"179,180"}},{"content":"<em>Activity logs</em>: records operations made on the resource","children":[],"payload":{"lines":"180,182"}}],"payload":{"lines":"175,176"}},{"content":"Manage costs for Azure AI services","children":[{"content":"<a href=\"https://azure.microsoft.com/en-us/pricing/calculator/\">Azure Pricing Calculator</a>","children":[{"content":"Estimate the cost of Azure services","children":[],"payload":{"lines":"185,186"}}],"payload":{"lines":"184,186"}},{"content":"<a href=\"https://docs.microsoft.com/en-us/azure/cost-management-billing/costs/quick-acm-cost-analysis?tabs=cost-analysis\">Azure Cost Management and Billing</a>","children":[{"content":"Monitor and analyze costs","children":[],"payload":{"lines":"187,188"}},{"content":"Create budgets and alerts","children":[],"payload":{"lines":"188,189"}},{"content":"Optimize costs","children":[],"payload":{"lines":"189,190"}},{"content":"Billing administrative tasks","children":[],"payload":{"lines":"190,192"}}],"payload":{"lines":"186,192"}}],"payload":{"lines":"182,183"}},{"content":"Manage account keys","children":[],"payload":{"lines":"192,193"}},{"content":"Protect account keys by using Azure Key Vault","children":[{"content":"You can use Azure Key Vault to securely develop Azure AI services applications.","children":[],"payload":{"lines":"199,200"}},{"content":"Key Vault enables you to store your authentication credentials in the cloud, and reduces the<br>\nchances that secrets may be accidentally leaked, because you won't store security information<br>\nin your application.","children":[{"content":"Navigate to your Azure resource in the Azure portal","children":[],"payload":{"lines":"203,204"}},{"content":"From the collapsible menu on the left, select <code>Keys</code> and <code>Endpoint</code>","children":[],"payload":{"lines":"204,205"}},{"content":"In Azure Key Vault, select <code>Objects</code> &gt; <code>Secrets</code>","children":[],"payload":{"lines":"205,206"}},{"content":"Select <code>Generate/Import</code>","children":[],"payload":{"lines":"206,207"}},{"content":"Enter a <em>name</em> for the secret and the <em>value</em> you want to store","children":[],"payload":{"lines":"207,209"}}],"payload":{"lines":"200,209"}}],"payload":{"lines":"197,198"}},{"content":"Manage authentication for an Azure AI Service resource","children":[{"content":"Each request to an Azure AI service must include an authentication header.","children":[{"content":"Authenticate with a single-service or multi-service resource key","children":[],"payload":{"lines":"212,213"}},{"content":"Authenticate with a token","children":[],"payload":{"lines":"213,214"}},{"content":"Authenticate with Microsoft Entra ID","children":[{"content":"This scenario provides Azure RBAC integration with Azure AI services.","children":[],"payload":{"lines":"215,217"}}],"payload":{"lines":"214,217"}}],"payload":{"lines":"211,217"}}],"payload":{"lines":"209,210"}},{"content":"Manage private communications","children":[{"content":"\n<p data-lines=\"219,222\">To secure your Azure AI services resource, you should first configure a rule to deny access to<br>\ntraffic from all networks, including internet traffic, by default. Then, configure rules that<br>\ngrant access to traffic from specific virtual networks.</p>","children":[{"content":"Go to the <strong>Azure AI services</strong> resource you want to secure","children":[],"payload":{"lines":"222,223"}},{"content":"Select <strong>Networking</strong>","children":[],"payload":{"lines":"223,224"}},{"content":"To deny access by default, under <strong>Firewalls</strong> and <strong>virtual networks</strong>,<br>\nselect <strong>Selected Networks and Private Endpoints</strong>.","children":[],"payload":{"lines":"224,227"}}],"payload":{"lines":"219,227"}},{"content":"\n<p data-lines=\"227,228\">To grant access to a virtual network with an existing network rule:</p>","children":[{"content":"","children":[{"content":"Go to the **Azure AI services **resource you want to secure.","children":[],"payload":{"lines":"228,229"}},{"content":"Select <strong>Networking</strong>","children":[],"payload":{"lines":"229,230"}},{"content":"Under <strong>Allow access from</strong>, select <strong>Add existing virtual network</strong>.","children":[],"payload":{"lines":"230,231"}},{"content":"Select the Virtual networks and Subnets options, and then select <strong>Enable</strong>.","children":[],"payload":{"lines":"231,232"}}],"payload":{"lines":"228,232"}},{"content":"\n<blockquote data-lines=\"232,233\">\n<p data-lines=\"232,233\">If a service endpoint for Azure AI services wasn't previously configured for the selected virtual network and subnets, you can configure it as part of this operation.</p>\n</blockquote>","children":[],"payload":{"lines":"232,233"}},{"content":"Select <strong>Save</strong> to apply your changes.","children":[],"payload":{"lines":"233,235"}}],"payload":{"lines":"227,235"}}],"payload":{"lines":"217,218"}}],"payload":{"lines":"166,167"}},{"content":"Create solutions for content delivery","children":[{"content":"Implement a text moderation solution with Azure AI Content Safety","children":[{"content":"\n<p data-lines=\"239,240\">Detect and filter harmful or inappropriate text content in applications</p>","children":[{"content":"","children":[{"content":"Get an API endpoint + subscription key","children":[],"payload":{"lines":"241,242"}},{"content":"Send a request to the endpoint with the subscription key and the text to analyze","children":[],"payload":{"lines":"242,243"}},{"content":"Get a response with the classification of the text as JSON","children":[],"payload":{"lines":"243,244"}}],"payload":{"lines":"241,244"}},{"content":"","children":[{"content":"Harm categories (e.g. hate and fairness, sexual, violence, self-harm)","children":[],"payload":{"lines":"244,245"}},{"content":"Severity level from 0 to 7 (e.g. safe, low, medium, high)","children":[],"payload":{"lines":"245,247"}}],"payload":{"lines":"244,247"}}],"payload":{"lines":"239,247"}}],"payload":{"lines":"237,238"}},{"content":"Implement an image moderation solution with Azure AI Content Safety","children":[{"content":"\n<p data-lines=\"249,250\">Detect and filter harmful or inappropriate images in applications</p>","children":[{"content":"","children":[{"content":"Get an API endpoint + subscription key","children":[],"payload":{"lines":"251,252"}},{"content":"Send a request to the endpoint with the subscription key and the image to analyze","children":[],"payload":{"lines":"252,253"}},{"content":"Get a response with the classification of the image as JSON","children":[],"payload":{"lines":"253,254"}}],"payload":{"lines":"251,254"}},{"content":"","children":[{"content":"Harm categories (e.g. hate and fairness, sexual, violence, self-harm)","children":[],"payload":{"lines":"254,255"}},{"content":"Severity level from 0 to 7 (e.g. safe, low, medium, high)","children":[],"payload":{"lines":"255,257"}}],"payload":{"lines":"254,257"}}],"payload":{"lines":"249,257"}}],"payload":{"lines":"247,248"}}],"payload":{"lines":"235,236"}}],"payload":{"lines":"12,13"}},{"content":"Implement computer vision solutions (15–20%)","children":[{"content":"Analyze images","children":[{"content":"Select visual features to meet image processing requirements","children":[{"content":"Create Azure AI custom vision training and prediction resources.","children":[],"payload":{"lines":"263,265"}}],"payload":{"lines":"261,262"}},{"content":"Detect objects in images and generate image tags","children":[{"content":"Create a new Custom Vision project","children":[],"payload":{"lines":"267,268"}},{"content":"Select Type Object Detection","children":[],"payload":{"lines":"268,269"}},{"content":"Select an available domain (General, Food, Landmarks, Retail, Logo etc.)","children":[],"payload":{"lines":"269,270"}},{"content":"Train and test the model","children":[],"payload":{"lines":"270,271"}},{"content":"Publish and consume the model","children":[],"payload":{"lines":"271,273"}}],"payload":{"lines":"265,266"}},{"content":"Include image analysis features in an image processing request","children":[{"content":"<mark>TODO</mark>","children":[],"payload":{"lines":"275,277"}}],"payload":{"lines":"273,274"}},{"content":"Interpret image processing responses","children":[{"content":"The service returns results in the form of an <a href=\"https://learn.microsoft.com/en-us/dotnet/api/microsoft.azure.cognitiveservices.vision.customvision.prediction.models.imageprediction?view=azure-dotnet\"><code>ImagePrediction</code></a> object.<br>\nThe <a href=\"https://learn.microsoft.com/en-us/dotnet/api/microsoft.azure.cognitiveservices.vision.customvision.prediction.models.imageprediction.predictions?view=azure-dotnet#microsoft-azure-cognitiveservices-vision-customvision-prediction-models-imageprediction-predictions\"><code>Predictions</code></a> property contains a list of <a href=\"https://learn.microsoft.com/en-us/dotnet/api/microsoft.azure.cognitiveservices.vision.customvision.prediction.models.predictionmodel?view=azure-dotnet\"><code>PredictionModel</code></a> objects, which each represents a<br>\nsingle object prediction. They include the <strong>name</strong> of the <strong>label</strong> and the bounding box<br>\ncoordinates where the object was detected in the image. Your app can then parse this data to,<br>\nfor example, display the image with labeled object fields on a screen.","children":[],"payload":{"lines":"279,285"}}],"payload":{"lines":"277,278"}},{"content":"Extract text from images using Azure AI Vision","children":[{"content":"Azure AI vision can extract text from images and handwritten text","children":[{"content":"<mark><a href=\"https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-ocr\">OCR for images (version 4.0)</a></mark>","children":[{"content":"<strong>Inputs</strong>: Images: General, in-the-wild images","children":[],"payload":{"lines":"289,290"}},{"content":"<strong>Examples</strong>: labels, street signs, and posters","children":[],"payload":{"lines":"290,291"}},{"content":"Optimized for general, non-document images with a performance-enhanced <strong>synchronous API</strong><br>\nthat makes it easier to embed OCR in your user experience scenarios.","children":[],"payload":{"lines":"291,293"}}],"payload":{"lines":"288,293"}},{"content":"<mark><a href=\"https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/concept-read\">Document Intelligence read model</a></mark>","children":[{"content":"<strong>Inputs</strong>:Documents: Digital and scanned, including images","children":[],"payload":{"lines":"294,295"}},{"content":"<strong>Examples</strong>: books, articles, and reports","children":[],"payload":{"lines":"295,296"}},{"content":"Optimized for text-heavy scanned and digital documents with an <strong>asynchronous API</strong> to help<br>\nautomate intelligent document processing at scale.","children":[],"payload":{"lines":"296,299"}}],"payload":{"lines":"293,299"}}],"payload":{"lines":"287,299"}}],"payload":{"lines":"285,286"}},{"content":"Convert handwritten text using Azure AI Vision","children":[{"content":"Microsoft's Read OCR engine can extract printed and handwritten text including mixed languages and writing styles.","children":[],"payload":{"lines":"301,303"}}],"payload":{"lines":"299,300"}}],"payload":{"lines":"259,260"}},{"content":"Implement custom computer vision models by using Azure AI Vision","children":[{"content":"Choose between image classification and object detection models","children":[{"content":"<strong>Image classification</strong>: Classify or assign a label to an image","children":[],"payload":{"lines":"307,308"}},{"content":"<strong>Object detection</strong>: Identify and locate objects in an image","children":[],"payload":{"lines":"308,309"}},{"content":"You can upload and tag your images to train the classifier or detector model.","children":[],"payload":{"lines":"309,310"}},{"content":"For both image classification and object detection, you need to:","children":[{"content":"Create a new project","children":[],"payload":{"lines":"311,312"}},{"content":"Name and describe it","children":[],"payload":{"lines":"312,313"}},{"content":"Select a project type: Classification or Object Detection","children":[],"payload":{"lines":"313,314"}},{"content":"Select an available domain (General, Food, Landmarks, Retail, Logo etc.)","children":[],"payload":{"lines":"314,315"}},{"content":"Train and test the model","children":[],"payload":{"lines":"315,316"}},{"content":"Publish and consume the model","children":[],"payload":{"lines":"316,318"}}],"payload":{"lines":"310,318"}}],"payload":{"lines":"305,306"}},{"content":"Label images","children":[{"content":"For image classification you need to select either:","children":[{"content":"Multilabel classification: Assign multiple labels to an image","children":[],"payload":{"lines":"321,322"}},{"content":"Multiclass classification: Assign a single label to an image","children":[],"payload":{"lines":"322,324"}}],"payload":{"lines":"320,324"}}],"payload":{"lines":"318,319"}},{"content":"Train a custom image model, including image classification and object detection","children":[{"content":"Select <code>train</code> button to start training the model","children":[],"payload":{"lines":"326,327"}},{"content":"The training process can take a few minutes to a few hours","children":[],"payload":{"lines":"327,328"}},{"content":"Monitor the training process and check the metrics via the performance tab","children":[],"payload":{"lines":"328,329"}},{"content":"Delete obsolete iterations","children":[],"payload":{"lines":"329,331"}}],"payload":{"lines":"324,325"}},{"content":"Evaluate custom vision model metrics","children":[{"content":"Available metrics:","children":[{"content":"<strong>Precision</strong>","children":[{"content":"A percentage value that indicates the proportion of true positive predictions in the<br>\ntotal number of positive predictions.","children":[],"payload":{"lines":"335,337"}}],"payload":{"lines":"334,337"}},{"content":"<strong>Recall</strong>","children":[{"content":"A percentage value that indicates the proportion of true positive predictions in the<br>\ntotal number of actual positive instances.","children":[],"payload":{"lines":"338,340"}}],"payload":{"lines":"337,340"}},{"content":"<strong>mAP</strong> (mean Average Precision) - Object Detection only","children":[{"content":"A metric that evaluates the precision-recall curve for object detection models.","children":[],"payload":{"lines":"341,342"}}],"payload":{"lines":"340,342"}}],"payload":{"lines":"333,342"}},{"content":"Additional metrics:","children":[{"content":"<strong>Probability threshold</strong>: The level of confidence that a prediction needs to have in order<br>\nto be considered correct (for the purposes of calculating precision and recall)","children":[],"payload":{"lines":"343,345"}},{"content":"<strong>Overlapping threshold</strong>: Sets the minimum allowed overlap between the predicted object's<br>\nbounding box and the actual user-entered bounding box. If the bounding boxes don't overlap to<br>\nthis degree, the prediction won't be considered correct.","children":[],"payload":{"lines":"345,349"}}],"payload":{"lines":"342,349"}}],"payload":{"lines":"331,332"}},{"content":"Publish a custom vision model","children":[{"content":"Make your model available for consumption by others by publishing it.","children":[{"content":"Select the Publish <code>✓</code> button","children":[],"payload":{"lines":"352,353"}},{"content":"Provide the model name and prediction resource","children":[],"payload":{"lines":"353,354"}},{"content":"Select the <code>Publish</code> button","children":[],"payload":{"lines":"354,356"}}],"payload":{"lines":"351,356"}}],"payload":{"lines":"349,350"}},{"content":"Consume a custom vision model","children":[{"content":"<mark>TODO</mark>","children":[],"payload":{"lines":"358,360"}}],"payload":{"lines":"356,357"}}],"payload":{"lines":"303,304"}},{"content":"Analyze videos","children":[{"content":"Use Azure AI Video Indexer to extract insights from a video or live stream","children":[{"content":"Analyze video content to extract topics, labels, named-entities, emotions, and scenes.","children":[],"payload":{"lines":"364,365"}},{"content":"A timeline is provided to navigate through the video content along with the dialogue and<br>\nspeaker identification.","children":[],"payload":{"lines":"365,368"}}],"payload":{"lines":"362,363"}},{"content":"Use Azure AI Vision Spatial Analysis to detect presence and movement of people in video","children":[{"content":"People counting","children":[],"payload":{"lines":"370,371"}},{"content":"Entrance and exit counting","children":[],"payload":{"lines":"371,372"}},{"content":"Social distancing and face/mask detection","children":[],"payload":{"lines":"372,374"}}],"payload":{"lines":"368,369"}}],"payload":{"lines":"360,361"}}],"payload":{"lines":"257,258"}},{"content":"Implement natural language processing solutions (30–35%)","children":[{"content":"Analyze text by using Azure AI Language","children":[{"content":"Extract key phrases","children":[{"content":"Identify the main points in a text","children":[{"content":"Create an Azure AI language resource","children":[],"payload":{"lines":"381,382"}},{"content":"Get the endpoint and subscription key","children":[],"payload":{"lines":"382,383"}},{"content":"Send a request to the endpoint with the subscription key and the raw text to analyze","children":[],"payload":{"lines":"383,384"}},{"content":"Get a response with the key phrases as JSON: stream or store locally.","children":[],"payload":{"lines":"384,385"}}],"payload":{"lines":"380,385"}},{"content":"3 consumption ways:","children":[{"content":"Language Studio","children":[],"payload":{"lines":"386,387"}},{"content":"REST API","children":[],"payload":{"lines":"387,388"}},{"content":"Docker container","children":[],"payload":{"lines":"388,390"}}],"payload":{"lines":"385,390"}}],"payload":{"lines":"378,379"}},{"content":"Extract entities","children":[{"content":"Entity linking: identify and disambiguate entities in text.","children":[{"content":"Different endpoint for entity linking.","children":[],"payload":{"lines":"393,394"}}],"payload":{"lines":"392,394"}},{"content":"Named entity recognition: identify and classify named entities in text.","children":[{"content":"Ex: person, location, organization, date, etc.","children":[],"payload":{"lines":"395,397"}}],"payload":{"lines":"394,397"}}],"payload":{"lines":"390,391"}},{"content":"Determine sentiment of text","children":[{"content":"<a href=\"https://learn.microsoft.com/en-us/azure/ai-services/language-service/sentiment-opinion-mining/overview?tabs=prebuilt\">Evaluate text and returns sentiment scores and labels for each sentence</a>","children":[{"content":"<strong>Sentiment analysis</strong>: Provides sentiment labels (such as \"negative\", \"neutral\" and<br>\n\"positive\") based on the highest confidence score found by the service at a sentence and<br>\ndocument-level.","children":[{"content":"This feature also returns confidence scores between 0 and 1 for each document &amp; sentences<br>\nwithin it for positive, neutral and negative sentiment.","children":[],"payload":{"lines":"403,405"}}],"payload":{"lines":"400,405"}},{"content":"<strong>Opinion mining</strong>: Also known as aspect-based sentiment analysis in Natural Language Processing<br>\n(NLP).","children":[{"content":"this feature provides more granular information about the opinions related to words<br>\n(such as the attributes of products or services) in text.","children":[],"payload":{"lines":"407,410"}}],"payload":{"lines":"405,410"}}],"payload":{"lines":"399,410"}}],"payload":{"lines":"397,398"}},{"content":"Detect the language used in text","children":[{"content":"Evaluates a text and returns scored language identifiers.","children":[{"content":"Large panel of languages supported including regional dialects.","children":[],"payload":{"lines":"413,414"}},{"content":"In case of mixed languages, the service will return the most used language with a low<br>\nconfidence score","children":[],"payload":{"lines":"414,417"}}],"payload":{"lines":"412,417"}}],"payload":{"lines":"410,411"}},{"content":"Detect personally identifiable information (PII) in text","children":[{"content":"Identify, categorize and redact sensitive information in unstructured text.","children":[{"content":"Create an Azure AI language resource","children":[],"payload":{"lines":"420,421"}},{"content":"Get the endpoint and subscription key","children":[],"payload":{"lines":"421,422"}},{"content":"Send a request to the endpoint with the subscription key and the raw text to analyze","children":[],"payload":{"lines":"422,423"}},{"content":"Get a response with the key phrases as JSON: stream or store locally.","children":[],"payload":{"lines":"423,424"}}],"payload":{"lines":"419,424"}},{"content":"API is stateless in synchronous mode and available for 24h in asynchronous mode.","children":[],"payload":{"lines":"424,426"}}],"payload":{"lines":"417,418"}}],"payload":{"lines":"376,377"}},{"content":"Process speech by using Azure AI Speech","children":[{"content":"Implement text-to-speech","children":[{"content":"Life-like speech synthesis (fluid and natural-sounding)","children":[],"payload":{"lines":"430,431"}},{"content":"Customizable voices","children":[],"payload":{"lines":"431,432"}},{"content":"Fined-grained audio controls (rate, pitch, pause, pronunciation etc.)","children":[],"payload":{"lines":"432,433"}},{"content":"Flexible deployment (cloud or containers)","children":[],"payload":{"lines":"433,435"}}],"payload":{"lines":"428,429"}},{"content":"Implement speech-to-text","children":[{"content":"Real-time transcription of audio streams into written text by using SSML<br>\n(Speech Synthesis Markup Language).","children":[{"content":"High quality transcription","children":[],"payload":{"lines":"439,440"}},{"content":"Flexible deployment","children":[],"payload":{"lines":"440,441"}},{"content":"Customizable models","children":[],"payload":{"lines":"441,442"}},{"content":"Production-ready","children":[],"payload":{"lines":"442,444"}}],"payload":{"lines":"437,444"}}],"payload":{"lines":"435,436"}},{"content":"Improve text-to-speech by using Speech Synthesis Markup Language (SSML)","children":[{"content":"SSML can be used to fine-tune text-to-speech models outputs.","children":[{"content":"SSML is a markup language that allows developers to control various aspects of speech<br>\nsynthesis, such as pronunciation, volume, pitch, rate, and more.","children":[],"payload":{"lines":"447,449"}}],"payload":{"lines":"446,449"}},{"content":"Custom neural voice (CNV) models can be used to create custom voices for text-to-speech<br>\napplications.","children":[{"content":"CNV models are trained on a speaker's voice data to create a custom voice that can be used<br>\nin text-to-speech applications.","children":[],"payload":{"lines":"451,454"}}],"payload":{"lines":"449,454"}}],"payload":{"lines":"444,445"}},{"content":"Implement custom speech solutions","children":[{"content":"Test custom speech solutions for Word Error Rate (WER) with accuracy testing and custom acoustic<br>\nmodels:","children":[{"content":"Needs improvement: &gt;30%","children":[],"payload":{"lines":"458,459"}},{"content":"Acceptable: ~20%","children":[],"payload":{"lines":"459,460"}},{"content":"Ready for production: &lt;10%","children":[],"payload":{"lines":"460,462"}}],"payload":{"lines":"456,462"}}],"payload":{"lines":"454,455"}},{"content":"Implement intent recognition","children":[{"content":"2 methods:","children":[{"content":"Pattern matching: for offline solutions","children":[{"content":"Create code and speech configuration","children":[],"payload":{"lines":"468,469"}},{"content":"Initialize the intent recognizer and declare entities as intent","children":[],"payload":{"lines":"469,470"}},{"content":"Enable recognition of intent","children":[],"payload":{"lines":"470,471"}},{"content":"Instruct code to stop on intent recognition","children":[],"payload":{"lines":"471,472"}},{"content":"Display results","children":[],"payload":{"lines":"472,473"}},{"content":"Publish","children":[],"payload":{"lines":"473,474"}}],"payload":{"lines":"467,474"}},{"content":"CLU (Conversational Language Understanding): prediction of intents","children":[{"content":"Create a new project by importing a JSON file","children":[],"payload":{"lines":"475,476"}},{"content":"Train model","children":[],"payload":{"lines":"476,477"}},{"content":"Choose training mode and data splitting","children":[],"payload":{"lines":"477,478"}},{"content":"Deploy model","children":[],"payload":{"lines":"478,479"}},{"content":"Use model to recognize intents from an audio stream","children":[],"payload":{"lines":"479,481"}}],"payload":{"lines":"474,481"}}],"payload":{"lines":"466,481"}}],"payload":{"lines":"462,463"}},{"content":"Implement keyword recognition","children":[{"content":"\n<p data-lines=\"483,484\">Detect word or short phrase within audio stream or content</p>","children":[{"content":"","children":[{"content":"Create a new project in speech studio","children":[],"payload":{"lines":"485,486"}},{"content":"Create a custom keyword:","children":[],"payload":{"lines":"486,487"}},{"content":"Create new model","children":[],"payload":{"lines":"487,488"}},{"content":"Provide name/description and the keyword","children":[],"payload":{"lines":"488,489"}},{"content":"Validate","children":[],"payload":{"lines":"489,490"}},{"content":"Select a model type and Create","children":[],"payload":{"lines":"490,492"}}],"payload":{"lines":"485,492"}},{"content":"","children":[{"content":"<strong>Basic</strong>: rapid prototyping","children":[],"payload":{"lines":"492,493"}},{"content":"<strong>Advanced</strong>: improved accuracy characteristics for product integration","children":[],"payload":{"lines":"493,495"}}],"payload":{"lines":"492,495"}},{"content":"","children":[{"content":"Select <strong>Tune</strong> to download the model","children":[],"payload":{"lines":"495,496"}},{"content":"This model can now be used","children":[],"payload":{"lines":"496,498"}}],"payload":{"lines":"495,498"}}],"payload":{"lines":"483,498"}}],"payload":{"lines":"481,482"}}],"payload":{"lines":"426,427"}},{"content":"Translate language","children":[{"content":"Resources","children":[{"content":"<a href=\"https://learn.microsoft.com/en-us/azure/ai-services/translator/\">Azure AI Translator documentation</a>","children":[],"payload":{"lines":"502,503"}},{"content":"<a href=\"https://github.com/retkowsky/azure-ai-translator\">Azure AI Translator demos</a>","children":[],"payload":{"lines":"503,505"}}],"payload":{"lines":"500,501","fold":1}},{"content":"Translate text and documents by using the Azure AI Translator service","children":[{"content":"2 distinct types of endpoints enable:","children":[{"content":"<strong>Text translation</strong>: Translate text between languages (real-time)","children":[{"content":"REST API cloud-based translator","children":[],"payload":{"lines":"509,510"}},{"content":"Docker container based translator","children":[],"payload":{"lines":"510,511"}},{"content":"Supported methods:","children":[{"content":"<strong>Languages</strong>: Returns a list of languages supported by Translate, Transliterate, and Dictionary<br>\nLookup operations. This request doesn't require authentication; just copy and paste the<br>\nfollowing GET request into your favorite REST API tool or browser:","children":[{"content":"<code>https://api.cognitive.microsofttranslator.com/languages?api-version=3.0</code>","children":[],"payload":{"lines":"515,516"}}],"payload":{"lines":"512,516"}},{"content":"<strong>Translate</strong>: Renders single source-language text to multiple target-language texts with a<br>\nsingle request.","children":[],"payload":{"lines":"516,518"}},{"content":"<strong>Transliterate</strong>: Converts characters or letters of a source language to the corresponding<br>\ncharacters or letters of a target language.","children":[],"payload":{"lines":"518,520"}},{"content":"<strong>Detect</strong>: Returns the source code language code and a boolean variable denoting whether the<br>\ndetected language is supported for text translation and transliteration.","children":[],"payload":{"lines":"520,522"}},{"content":"<strong>Dictionary lookup</strong>: Returns equivalent words for the source term in the target language.","children":[],"payload":{"lines":"522,523"}},{"content":"<strong>Dictionary example</strong>: Returns grammatical structure and context examples for the source<br>\nterm and target term pair.","children":[],"payload":{"lines":"523,525"}}],"payload":{"lines":"511,525"}}],"payload":{"lines":"508,525"}},{"content":"<strong>Document translation</strong>: Translate documents between languages (asynchronous)","children":[{"content":"REST API cloud-based translator","children":[],"payload":{"lines":"526,527"}},{"content":"Client library SDK","children":[],"payload":{"lines":"527,528"}},{"content":"Supported methods:","children":[{"content":"<strong>Translate large files</strong>: Translate whole documents asynchronously.","children":[],"payload":{"lines":"529,530"}},{"content":"<strong>Translate numerous files</strong>: Translate multiple files across all supported languages and<br>\ndialects while preserving document structure and data format.","children":[],"payload":{"lines":"530,532"}},{"content":"<strong>Preserve source file presentation</strong>: Translate files while preserving the original layout<br>\nand format.","children":[],"payload":{"lines":"532,534"}},{"content":"<strong>Apply custom translation</strong>: Translate documents using general and custom translation models.","children":[],"payload":{"lines":"534,535"}},{"content":"<strong>Apply custom glossaries</strong>: Translate documents using custom glossaries.","children":[],"payload":{"lines":"535,536"}},{"content":"<strong>Automatically detect document language</strong>: Let the Document Translation service determine<br>\nthe language of the document.","children":[],"payload":{"lines":"536,538"}},{"content":"<strong>Translate documents with content in multiple languages</strong>: Use the autodetect feature to<br>\ntranslate documents with content in multiple languages into your target language.","children":[],"payload":{"lines":"538,541"}}],"payload":{"lines":"528,541"}}],"payload":{"lines":"525,541"}}],"payload":{"lines":"507,541"}}],"payload":{"lines":"505,506"}},{"content":"Implement custom translation, including training, improving, and publishing a custom model","children":[{"content":"Train a custom model:","children":[{"content":"Select <strong>train</strong> model, enter sample data and select <strong>full training</strong>","children":[],"payload":{"lines":"544,545"}},{"content":"Select sample-source language, target language and review training costs","children":[],"payload":{"lines":"545,546"}},{"content":"Select <strong>Train now</strong> then <strong>Train</strong> to start training","children":[],"payload":{"lines":"546,547"}},{"content":"Once trained, select <strong>Model details</strong> to review the model","children":[],"payload":{"lines":"547,548"}}],"payload":{"lines":"543,548"}},{"content":"Test and publish a custom model","children":[{"content":"Select <strong>Test model</strong>, enter sample data","children":[],"payload":{"lines":"549,550"}},{"content":"Test (human evaluation) the translation","children":[],"payload":{"lines":"550,551"}},{"content":"Select <strong>Publish model</strong> to make the model available","children":[],"payload":{"lines":"551,552"}},{"content":"Select a region and validate.","children":[],"payload":{"lines":"552,554"}}],"payload":{"lines":"548,554"}}],"payload":{"lines":"541,542"}},{"content":"Translate speech-to-speech by using the Azure AI Speech service","children":[{"content":"Speech-to-speech service can translate an audio stream/input to another language as an audio output.","children":[{"content":"Works in real-time.","children":[],"payload":{"lines":"557,559"}}],"payload":{"lines":"556,559"}}],"payload":{"lines":"554,555"}},{"content":"Translate speech-to-text by using the Azure AI Speech service","children":[{"content":"4 translation services for Speech-to-text:","children":[{"content":"<mark>Speech translator API</mark>","children":[{"content":"Typically used for real-time translation of spoken languages","children":[],"payload":{"lines":"563,564"}}],"payload":{"lines":"562,564"}},{"content":"<mark>Speech CLI</mark>","children":[{"content":"Experiment with minimal code solution","children":[],"payload":{"lines":"565,566"}}],"payload":{"lines":"564,566"}},{"content":"<mark>Speech SDK</mark>","children":[{"content":"Use in your own applications","children":[],"payload":{"lines":"567,568"}}],"payload":{"lines":"566,568"}},{"content":"<mark>Speech Studio</mark>","children":[{"content":"Typically used to test and tune speech services","children":[],"payload":{"lines":"569,571"}}],"payload":{"lines":"568,571"}}],"payload":{"lines":"561,571"}}],"payload":{"lines":"559,560"}},{"content":"Translate to multiple languages simultaneously","children":[],"payload":{"lines":"571,572"}}],"payload":{"lines":"498,499"}},{"content":"Implement and manage a language understanding model by using Azure AI Language","children":[{"content":"Create intents and add utterances","children":[{"content":"<strong>Intent</strong>: action or goal expressed in a user's utterance","children":[],"payload":{"lines":"577,578"}},{"content":"<strong>Utterance</strong>: spoken or written phrases","children":[],"payload":{"lines":"578,580"}}],"payload":{"lines":"575,576"}},{"content":"Create entities","children":[{"content":"Word or phrase within utterances that can be identified and extracted","children":[{"content":"<strong>Learned component</strong>: enables predictions based on context learned while labelling of utterances","children":[],"payload":{"lines":"583,584"}},{"content":"<strong>List component</strong>: Fixed ser of related words with their synonyms","children":[],"payload":{"lines":"584,585"}},{"content":"<strong>Prebuilt component</strong>: Built-in entities like date, time, number, etc.","children":[],"payload":{"lines":"585,586"}},{"content":"<strong>Regex component</strong>: Regular expression to match entities","children":[],"payload":{"lines":"586,587"}}],"payload":{"lines":"582,587"}},{"content":"To create entities:","children":[{"content":"Navigate to <strong>Entities</strong> pivot","children":[],"payload":{"lines":"588,589"}},{"content":"Select <strong>Add</strong> and type entity name","children":[],"payload":{"lines":"589,590"}},{"content":"Define composition settings","children":[],"payload":{"lines":"590,591"}},{"content":"Attach a <em>Learned</em>, <em>Prebuilt</em> or <em>List</em> component","children":[],"payload":{"lines":"591,593"}}],"payload":{"lines":"587,593"}}],"payload":{"lines":"580,581"}},{"content":"Train, evaluate, deploy, and test a language understanding model","children":[{"content":"CLU can be used to build a custom <em>natural language understanding model</em> which predicts intention and extract information of utterances.","children":[],"payload":{"lines":"595,596"}},{"content":"Creation process:","children":[{"content":"Select data and define schema","children":[],"payload":{"lines":"597,598"}},{"content":"Label data","children":[],"payload":{"lines":"598,599"}},{"content":"Train model","children":[],"payload":{"lines":"599,600"}},{"content":"View model performance results","children":[],"payload":{"lines":"600,601"}},{"content":"Tune the model","children":[],"payload":{"lines":"601,602"}},{"content":"Deploy","children":[],"payload":{"lines":"602,603"}},{"content":"Predict intents and entities","children":[],"payload":{"lines":"603,605"}}],"payload":{"lines":"596,605"}}],"payload":{"lines":"593,594"}},{"content":"Optimize a language understanding model","children":[{"content":"Ensure training data set is representative and sufficient","children":[{"content":"Insufficient data can lead to overfitting and lower accuracy","children":[],"payload":{"lines":"608,609"}},{"content":"Adding more labeled data can improve the accuracy of the model","children":[],"payload":{"lines":"609,610"}}],"payload":{"lines":"607,610"}},{"content":"Ensure all entities are covered in test data","children":[{"content":"Absence of labeled instance can reduce accuracy of model evaluation","children":[],"payload":{"lines":"611,612"}},{"content":"Ensure all entities are covered in the test data","children":[],"payload":{"lines":"612,613"}}],"payload":{"lines":"610,613"}},{"content":"Fix unclear or ambiguous distinction between intents and entities","children":[{"content":"Similar data for different intents can lead to confusion","children":[],"payload":{"lines":"614,615"}},{"content":"You can solve this by merging similar entities or adding more examples","children":[],"payload":{"lines":"615,617"}}],"payload":{"lines":"613,617"}}],"payload":{"lines":"605,606"}},{"content":"Consume a language model from a client application","children":[{"content":"Azure AI language models can be consumed from a client application using the REST API or SDKs.","children":[{"content":"This enables users to use natural language as input to interact with the application.","children":[],"payload":{"lines":"620,621"}},{"content":"User's intent and entities are extracted and processed by the model to provide the desired output.","children":[],"payload":{"lines":"621,622"}},{"content":"Application performs the necessary actions.","children":[],"payload":{"lines":"622,624"}}],"payload":{"lines":"619,624"}}],"payload":{"lines":"617,618"}},{"content":"Backup and recover language understanding models","children":[{"content":"Export replicas of language understanding models to backup and recover them in case of data loss.","children":[{"content":"Export","children":[{"content":"Create a <code>POST</code> request with <code>Ocp-Apim-Subscription-Key</code> to create export task","children":[],"payload":{"lines":"628,629"}},{"content":"Use <code>GET</code> request to get a status of the export task","children":[],"payload":{"lines":"629,630"}},{"content":"Use <code>GET</code> request to download the exported model","children":[],"payload":{"lines":"630,631"}}],"payload":{"lines":"627,631"}},{"content":"Import","children":[{"content":"Create a <code>POST</code> request with <code>Ocp-Apim-Subscription-Key</code> to create import task","children":[{"content":"Body should contain the exported model as JSON","children":[],"payload":{"lines":"633,634"}}],"payload":{"lines":"632,634"}},{"content":"Use <code>GET</code> request to get a status of the import task","children":[],"payload":{"lines":"634,635"}},{"content":"Wait for successful completion of the task","children":[],"payload":{"lines":"635,638"}}],"payload":{"lines":"631,638"}}],"payload":{"lines":"626,638"}}],"payload":{"lines":"624,625"}}],"payload":{"lines":"573,574"}},{"content":"Create a custom question answering solution by using Azure AI Language","children":[{"content":"Create a custom question answering project","children":[{"content":"Enable custom question answering","children":[],"payload":{"lines":"642,643"}},{"content":"Create a new project with a name and a language","children":[],"payload":{"lines":"643,644"}},{"content":"Add question-answer pairs from source URLs or manually","children":[],"payload":{"lines":"644,646"}}],"payload":{"lines":"640,641"}},{"content":"Add question-and-answer pairs manually","children":[{"content":"In this case, you need to type the question and the answer manually.","children":[],"payload":{"lines":"648,650"}}],"payload":{"lines":"646,647"}},{"content":"Import sources","children":[{"content":"Use different sources to populate Azure Question Answering project:","children":[{"content":"Structured documents (manuals, guidelines, etc.)","children":[{"content":"Questions will be derived from the headings and subheadings of the document","children":[],"payload":{"lines":"654,655"}},{"content":"Answers will be derived from the subsequent text","children":[],"payload":{"lines":"655,656"}}],"payload":{"lines":"653,656"}},{"content":"Unstructured documents (articles, blogs, etc.)","children":[],"payload":{"lines":"656,657"}},{"content":"Question-and-answer documents (FAQs, etc.)","children":[{"content":"<code>.docx</code>, <code>.pdf</code>, <code>.txt</code>, <code>.html</code>, <code>.tsv</code>, <code>.csv</code>...","children":[],"payload":{"lines":"658,660"}}],"payload":{"lines":"657,660"}}],"payload":{"lines":"652,660"}}],"payload":{"lines":"650,651"}},{"content":"Train, test and publish a knowledge base","children":[{"content":"In the knowledge base, source documents are imported as Questions. You can amend the questions<br>\nand answers as needed.","children":[],"payload":{"lines":"662,664"}},{"content":"Select <strong>Save and train</strong>, then <strong>Test</strong>","children":[],"payload":{"lines":"664,665"}},{"content":"A test version of the knowledge base is created and you can analyze it with the <strong>Inspect</strong> button","children":[],"payload":{"lines":"665,666"}},{"content":"You can <strong>Publish</strong> the knowledge base to make it available for consumption through REST endpoint","children":[],"payload":{"lines":"666,668"}}],"payload":{"lines":"660,661"}},{"content":"Create a multi-turn conversation","children":[{"content":"Multi-turn conversations are dialogues between a user and a bot that require multiple steps to<br>\ncomplete.","children":[],"payload":{"lines":"670,672"}},{"content":"To create:","children":[{"content":"Select <strong>Add follow-up prompts</strong> in the knowledge base","children":[],"payload":{"lines":"673,674"}},{"content":"Fill details of the prompt","children":[],"payload":{"lines":"674,675"}},{"content":"<strong>Create link to new pair</strong>","children":[],"payload":{"lines":"675,676"}},{"content":"<strong>Save</strong>","children":[],"payload":{"lines":"676,677"}}],"payload":{"lines":"672,677"}},{"content":"Multiple follow-up prompts can be added to a single question by repeating the same process.","children":[],"payload":{"lines":"677,679"}}],"payload":{"lines":"668,669"}},{"content":"Add alternate phrasing","children":[{"content":"Add alternate questions with differences in the sentence structure or wording to improve the<br>\naccuracy of the model.","children":[],"payload":{"lines":"681,684"}}],"payload":{"lines":"679,680"}},{"content":"Add chit-chat to a knowledge base","children":[{"content":"Chit-chat is a feature that allows the bot to engage in casual conversation with the user.","children":[{"content":"Provide bot the ability to answer question in a way that fits your brand","children":[],"payload":{"lines":"687,688"}},{"content":"Set a personality for the bot","children":[],"payload":{"lines":"688,689"}},{"content":"Automatically add simple question-answer pairs to the knowledge base","children":[],"payload":{"lines":"689,691"}}],"payload":{"lines":"686,691"}}],"payload":{"lines":"684,685"}},{"content":"Export a knowledge base","children":[{"content":"Exporting a knowledge base allows you to save a copy of the knowledge base for:","children":[{"content":"Backup purpose","children":[],"payload":{"lines":"694,695"}},{"content":"CI/CD integration","children":[],"payload":{"lines":"695,696"}},{"content":"Deployment region mobility","children":[],"payload":{"lines":"696,697"}}],"payload":{"lines":"693,697"}},{"content":"Steps:","children":[{"content":"Open the <em>custom question answering</em> project","children":[],"payload":{"lines":"698,699"}},{"content":"Select <strong>Export</strong>","children":[],"payload":{"lines":"699,700"}},{"content":"Select the export format (<code>.xlsx</code> or <code>.tsv</code>) that will be exported in a <code>.zip</code> file","children":[],"payload":{"lines":"700,702"}}],"payload":{"lines":"697,702"}}],"payload":{"lines":"691,692"}},{"content":"Create a multi-language question answering solution","children":[{"content":"Multi-language question answering solutions can be created by training the model with data in<br>\nmultiple languages.","children":[{"content":"The model can be trained with data in multiple languages to support multi-language question<br>\nanswering solutions.","children":[],"payload":{"lines":"706,708"}}],"payload":{"lines":"704,708"}},{"content":"Steps:","children":[{"content":"When creating the new <em>custom question answering</em> project:","children":[],"payload":{"lines":"709,710"}},{"content":"\n<blockquote data-lines=\"710,711\">\n<p data-lines=\"710,711\"><em>I want to select the language when I create a project in this resource</em></p>\n</blockquote>","children":[],"payload":{"lines":"710,711"}},{"content":"Enter basic information and create the project","children":[],"payload":{"lines":"711,712"}},{"content":"Add sources to deploy the project","children":[],"payload":{"lines":"712,714"}}],"payload":{"lines":"708,714"}}],"payload":{"lines":"702,703"}}],"payload":{"lines":"638,639"}}],"payload":{"lines":"374,375"}},{"content":"Implement knowledge mining and document intelligence solutions (10–15%)","children":[{"content":"Implement an Azure AI Search solution","children":[{"content":"Provision an Azure AI Search resource","children":[{"content":"Azure Cognitive Search (formerly known as “Azure Search”) is a cloud search service that gives<br>\ndevelopers infrastructure, APIs, and tools for building a rich search experience over private,<br>\nheterogeneous content in web, mobile, and enterprise applications.","children":[],"payload":{"lines":"720,723"}},{"content":"On the search service itself, the two primary workloads are indexing and querying.","children":[{"content":"<strong>Indexing</strong> engine","children":[{"content":"Intake process that loads content into your search service and makes it searchable.","children":[],"payload":{"lines":"725,726"}},{"content":"Internally, inbound text is processed into tokens and stored in inverted indexes, and inbound<br>\nvectors are stored in vector indexes.","children":[],"payload":{"lines":"726,728"}},{"content":"The document format that Azure AI Search can index is JSON. You can upload JSON documents<br>\nthat you've assembled, or use an indexer to retrieve and serialize your data into JSON.","children":[],"payload":{"lines":"728,730"}},{"content":"Applied AI through a <strong>skillset</strong> extends indexing with image and language models.","children":[{"content":"If you have images or large unstructured text in source document, you can attach skills<br>\nthat perform OCR, describe images, infer structure, translate text and more.","children":[],"payload":{"lines":"731,733"}},{"content":"You can also attach skills that perform data chunking and vectorization.","children":[],"payload":{"lines":"733,734"}}],"payload":{"lines":"730,734"}}],"payload":{"lines":"724,734"}},{"content":"<strong>Query engine</strong> is used when your client app sends query requests to a search service<br>\nand handles responses. All query execution is over a search index that you control.","children":[{"content":"<strong>Semantic ranking</strong> is an extension of query execution. It adds secondary ranking,<br>\nusing language understanding to reevaluate a result set, promoting the most semantically<br>\nrelevant results to the top.","children":[],"payload":{"lines":"736,740"}}],"payload":{"lines":"734,740"}}],"payload":{"lines":"723,740"}}],"payload":{"lines":"718,719"}},{"content":"Create data sources","children":[{"content":"Azure AI Search can index content from a variety of data sources:","children":[{"content":"Azure Storage (Blobs, Tables)","children":[],"payload":{"lines":"743,744"}},{"content":"Azure Cosmos DB","children":[],"payload":{"lines":"744,745"}},{"content":"Azure SQL Database, managed instance or SQL server","children":[],"payload":{"lines":"745,746"}}],"payload":{"lines":"742,746"}},{"content":"Both <em>push</em> and <em>pull</em> methods are supported.","children":[],"payload":{"lines":"746,748"}}],"payload":{"lines":"740,741"}},{"content":"Create an index","children":[{"content":"An <strong>index</strong> is a collection of JSON objects with unique keys and one or more fields.","children":[],"payload":{"lines":"750,751"}},{"content":"Index attributes can be:","children":[{"content":"Searchable: Full-text search","children":[],"payload":{"lines":"752,753"}},{"content":"Filterable","children":[],"payload":{"lines":"753,754"}},{"content":"Facetable: Used for aggregations/categorization and hit count","children":[],"payload":{"lines":"754,755"}},{"content":"Sortable","children":[],"payload":{"lines":"755,756"}},{"content":"Retrievable: Enables the field to be returned in search results or hidden from them.","children":[],"payload":{"lines":"756,758"}}],"payload":{"lines":"751,758"}}],"payload":{"lines":"748,749"}},{"content":"Define a skillset","children":[{"content":"A <strong>skillset</strong> is a reusable object in Azure AI Search that's attached to an indexer.","children":[{"content":"Contains one or more skills that call built-in AI or external custom processing over documents<br>\nretrieved from an external data source.","children":[],"payload":{"lines":"761,763"}}],"payload":{"lines":"760,763"}},{"content":"Steps:","children":[{"content":"Document Cracking","children":[],"payload":{"lines":"764,765"}},{"content":"Field mappings","children":[],"payload":{"lines":"765,766"}},{"content":"Skillset execution","children":[],"payload":{"lines":"766,767"}},{"content":"Output field mappings","children":[],"payload":{"lines":"767,768"}},{"content":"Push to index","children":[],"payload":{"lines":"768,769"}}],"payload":{"lines":"763,769"}},{"content":"Up to 30 skills per skillset","children":[],"payload":{"lines":"769,770"}},{"content":"Can repeat skills","children":[],"payload":{"lines":"770,771"}},{"content":"Support chained operations, looping and branching","children":[],"payload":{"lines":"771,773"}}],"payload":{"lines":"758,759"}},{"content":"Implement custom skills and include them in a skillset","children":[{"content":"An AI enrichment pipeline can include both built-in skills and custom skills that you personally<br>\ncreate and publish.","children":[],"payload":{"lines":"775,777"}},{"content":"Your custom code executes externally from the search service (for example, as an Azure function),<br>\nbut accepts inputs and sends outputs to the skillset just like any other skill.","children":[],"payload":{"lines":"777,779"}},{"content":"Following data are required to setup a new custom skill in a skillset:","children":[{"content":"<code>uri</code>","children":[],"payload":{"lines":"780,781"}},{"content":"<code>httpMethod</code> (PUT or POST)","children":[],"payload":{"lines":"781,782"}},{"content":"<code>httpHeaders</code>","children":[],"payload":{"lines":"782,783"}},{"content":"<code>timeout</code> (default 30s)","children":[],"payload":{"lines":"783,784"}},{"content":"<code>batchSize</code>: data records to send to the skill at once (1000 per default)","children":[],"payload":{"lines":"784,785"}},{"content":"<code>degreeOfParallelism</code>: maximum number of concurrent requests for this endpoint<br>\n(between 1 and 10, default 5)","children":[],"payload":{"lines":"785,787"}},{"content":"For managed-identity connections:","children":[{"content":"<code>resourceId</code>","children":[],"payload":{"lines":"788,789"}},{"content":"<code>authResourceId</code>","children":[],"payload":{"lines":"789,791"}}],"payload":{"lines":"787,791"}}],"payload":{"lines":"779,791"}}],"payload":{"lines":"773,774"}},{"content":"Create and run an indexer","children":[{"content":"An indexer definition consists of properties that uniquely identify the <strong>indexer</strong>,<br>\nspecify which <strong>data source</strong> and <strong>index</strong> to use, and provide other configuration options<br>\nthat influence run time behaviors, including whether the indexer runs on demand or on a schedule.","children":[],"payload":{"lines":"793,796"}},{"content":"Extracts and serializes data from a data source, passing it to a search service for data ingestion.","children":[],"payload":{"lines":"796,798"}}],"payload":{"lines":"791,792"}},{"content":"Query an index, including syntax, sorting, filtering, and wildcards","children":[{"content":"<strong>Full text search semantics</strong> based on <em>Lucene</em> query syntax over the index.","children":[{"content":"<a href=\"https://lucene.apache.org/core/6_6_1/queryparser/org/apache/lucene/queryparser/simple/SimpleQueryParser.html\">Simple Lucene Query Parser</a>","children":[],"payload":{"lines":"801,802"}},{"content":"<a href=\"https://lucene.apache.org/core/6_6_1/queryparser/org/apache/lucene/queryparser/classic/package-summary.html\">Full Lucene Query Syntax</a>: for specialized query forms: wildcard, fuzzy search, proximity search, regular expressions.","children":[],"payload":{"lines":"802,803"}}],"payload":{"lines":"800,803"}},{"content":"Queries are processed in 4 stages:","children":[{"content":"Query parsing","children":[],"payload":{"lines":"804,805"}},{"content":"Lexical analysis","children":[],"payload":{"lines":"805,806"}},{"content":"Document retrieval","children":[],"payload":{"lines":"806,807"}},{"content":"Scoring","children":[],"payload":{"lines":"807,809"}}],"payload":{"lines":"803,809"}}],"payload":{"lines":"798,799"}},{"content":"Manage Knowledge Store projections, including file, object, and table projections","children":[{"content":"Projection is a way to define the shape of the data that you want to retrieve from the index.","children":[{"content":"Enriched documents are stored in the knowledge store.","children":[],"payload":{"lines":"812,813"}},{"content":"Useful for knowledge mining scenarios.","children":[],"payload":{"lines":"813,814"}},{"content":"Projections can be read from 3 types of sources:","children":[{"content":"Files","children":[],"payload":{"lines":"815,816"}},{"content":"Objects","children":[],"payload":{"lines":"816,817"}},{"content":"Tables","children":[],"payload":{"lines":"817,819"}}],"payload":{"lines":"814,819"}}],"payload":{"lines":"811,819"}}],"payload":{"lines":"809,810"}}],"payload":{"lines":"716,717"}},{"content":"Implement an Azure AI Document Intelligence solution","children":[{"content":"Provision a Document Intelligence resource","children":[{"content":"Azure AI Document Intelligence is a cloud service that uses machine learning to extract<br>\ninformation from documents.","children":[],"payload":{"lines":"823,826"}}],"payload":{"lines":"821,822"}},{"content":"Use prebuilt models to extract data from documents","children":[{"content":"Prebuilt models are trained on a wide range of document types and can extract information<br>\nfrom documents with minimal configuration:","children":[{"content":"Receipts","children":[],"payload":{"lines":"830,831"}},{"content":"Invoices","children":[],"payload":{"lines":"831,832"}},{"content":"Business cards","children":[],"payload":{"lines":"832,833"}},{"content":"Identity documents","children":[],"payload":{"lines":"833,834"}},{"content":"Contracts","children":[],"payload":{"lines":"834,835"}},{"content":"Tax forms","children":[],"payload":{"lines":"835,836"}},{"content":"Vaccination cards","children":[],"payload":{"lines":"836,837"}},{"content":"and more...","children":[],"payload":{"lines":"837,839"}}],"payload":{"lines":"828,839"}}],"payload":{"lines":"826,827"}},{"content":"Implement a custom document intelligence model","children":[{"content":"You can train custom models to classify and extract information from documents that are specific<br>\nto your organization.","children":[{"content":"<strong>Custom extraction models</strong> can be trained to extract information from documents that are specific<br>\nto your organization.","children":[],"payload":{"lines":"843,845"}},{"content":"<strong>Custom classification models</strong> can be trained to classify documents based on their content.","children":[],"payload":{"lines":"845,846"}}],"payload":{"lines":"841,846"}},{"content":"Train, test, and publish a custom document intelligence model:","children":[{"content":"Create a new project in Document Intelligence Studio","children":[],"payload":{"lines":"847,848"}},{"content":"Label data","children":[],"payload":{"lines":"848,849"}},{"content":"Train the model","children":[],"payload":{"lines":"849,850"}},{"content":"Test the model","children":[],"payload":{"lines":"850,852"}}],"payload":{"lines":"846,852"}}],"payload":{"lines":"839,840"}},{"content":"Create a composed document intelligence model","children":[{"content":"Composed models in Azure AI Document Intelligence enable users to submit a form when<br>\nthey don't know which is the best model to use.","children":[{"content":"Once you've created a set of custom models, you must assemble them into a composed model.","children":[{"content":"You can do this in a GUI by using Azure AI Document Intelligence Studio,","children":[],"payload":{"lines":"857,858"}},{"content":"or by using the <code>StartCreateComposedModelAsync()</code> method in custom code.","children":[],"payload":{"lines":"858,859"}}],"payload":{"lines":"856,859"}},{"content":"Creation parameters:","children":[{"content":"<strong>Model IDs</strong>: The IDs of the custom models that you want to include in the composed model.","children":[],"payload":{"lines":"860,861"}},{"content":"<strong>Model Name</strong>: The name of the composed model.","children":[],"payload":{"lines":"861,862"}}],"payload":{"lines":"859,862"}},{"content":"GUI provides a method to create composed models by selecting the models to include.","children":[],"payload":{"lines":"862,864"}}],"payload":{"lines":"854,864"}}],"payload":{"lines":"852,853"}},{"content":"Implement a document intelligence model as a custom Azure AI Search skill","children":[{"content":"Once your document intelligence model is ready, you can integrate it as a custom skill in<br>\nAzure AI Search.","children":[{"content":"Enrich your index with fields that your Azure AI Document Intelligence models are trained<br>\nto extract.","children":[],"payload":{"lines":"868,870"}},{"content":"To implement this:","children":[{"content":"In AI Search resource: select the <em>Skillsets</em> tab","children":[],"payload":{"lines":"871,872"}},{"content":"Select <em>Add skillset</em>","children":[],"payload":{"lines":"872,873"}},{"content":"Provide the Skillset definition (JSON)","children":[],"payload":{"lines":"873,874"}},{"content":"Save.","children":[],"payload":{"lines":"874,876"}}],"payload":{"lines":"870,876"}}],"payload":{"lines":"866,876"}}],"payload":{"lines":"864,865"}}],"payload":{"lines":"819,820"}}],"payload":{"lines":"714,715"}},{"content":"Implement generative AI solutions (10–15%)","children":[{"content":"Use Azure OpenAI Service to generate content","children":[{"content":"Provision an Azure OpenAI Service resource","children":[{"content":"Create an Azure OpenAI resource to access the OpenAI API and use it to generate content:","children":[{"content":"Identify subscription, resource group, region, and pricing tier","children":[],"payload":{"lines":"883,884"}},{"content":"Configure network security","children":[],"payload":{"lines":"884,885"}},{"content":"Confirm configuration to deploy the resource","children":[],"payload":{"lines":"885,886"}}],"payload":{"lines":"882,886"}},{"content":"By CLI:","children":[{"content":"\n<pre><code class=\"language-bash\">az cognitiveservices account create -n &lt;resource-name&gt; -g &lt;resource-group&gt; \\n\n--subscription &lt;subscription-id&gt; --location &lt;location&gt; --kind OpenAI --sku &lt;sku&gt;\n</code></pre>","children":[],"payload":{"lines":"887,892"}}],"payload":{"lines":"886,892"}}],"payload":{"lines":"880,881"}},{"content":"Select and deploy an Azure OpenAI model","children":[{"content":"Azure OpenAI provides access to a range of models that can be used to generate content:","children":[{"content":"GPT-4: Newest model for natural language and code generation","children":[],"payload":{"lines":"895,896"}},{"content":"GPT-3.5: Natural language and code generation","children":[],"payload":{"lines":"896,897"}},{"content":"DALL-E: Image generation","children":[],"payload":{"lines":"897,898"}},{"content":"Embeddings: Similarity, text and code search etc.","children":[],"payload":{"lines":"898,899"}}],"payload":{"lines":"894,899"}},{"content":"Deploy a model:","children":[{"content":"Select subscription and OpenAI resource","children":[],"payload":{"lines":"900,901"}},{"content":"Create a new deployment:","children":[{"content":"Select the model","children":[],"payload":{"lines":"902,903"}},{"content":"Add a deployment name","children":[],"payload":{"lines":"903,904"}},{"content":"Setting advanced features like content filtering, token rate limits, etc.","children":[],"payload":{"lines":"904,905"}}],"payload":{"lines":"901,905"}}],"payload":{"lines":"899,905"}},{"content":"By CLI:","children":[{"content":"\n<pre><code class=\"language-bash\">az cognitiveservices account deployment create -n &lt;model-name&gt; -g &lt;resource-group&gt; \\n\n--deployment-name &lt;deployment-name&gt; --model-name &lt;model-name&gt; \\n\n--model-version &lt;model-version&gt; --model-format <span class=\"hljs-string\">\"OpenAI\"</span> \\n\n--scale-settings-scale-type <span class=\"hljs-string\">\"Standard\"</span>\n</code></pre>","children":[],"payload":{"lines":"906,913"}}],"payload":{"lines":"905,913"}}],"payload":{"lines":"892,893"}},{"content":"Submit prompts to generate natural language","children":[{"content":"You can submit prompt for multiple purposes:","children":[{"content":"Classifying content","children":[],"payload":{"lines":"916,917"}},{"content":"Generating new content","children":[],"payload":{"lines":"917,918"}},{"content":"Transformation and translation","children":[],"payload":{"lines":"918,919"}},{"content":"Summarization","children":[],"payload":{"lines":"919,920"}},{"content":"Continuation","children":[],"payload":{"lines":"920,921"}},{"content":"Question answering","children":[],"payload":{"lines":"921,922"}},{"content":"Chat","children":[],"payload":{"lines":"922,923"}},{"content":"and more...","children":[],"payload":{"lines":"923,925"}}],"payload":{"lines":"915,925"}}],"payload":{"lines":"913,914"}},{"content":"Submit prompts to generate code","children":[{"content":"Use prompt engineering to define precisly the code you want to generate:","children":[{"content":"Define the problem","children":[],"payload":{"lines":"928,929"}},{"content":"Define the input","children":[],"payload":{"lines":"929,930"}},{"content":"Define the output","children":[],"payload":{"lines":"930,931"}},{"content":"Define the constraints","children":[],"payload":{"lines":"931,932"}},{"content":"Define the evaluation metric","children":[],"payload":{"lines":"932,933"}}],"payload":{"lines":"927,933"}},{"content":"Break down complex problems into smaller, more manageable parts","children":[],"payload":{"lines":"933,935"}}],"payload":{"lines":"925,926"}},{"content":"Use the DALL-E model to generate images","children":[{"content":"DALL-E is a model that can generate images from textual descriptions:","children":[{"content":"Uses Neural network based model","children":[],"payload":{"lines":"938,939"}},{"content":"Uses Natural Language Processing (NLP) to understand the textual description","children":[],"payload":{"lines":"939,940"}},{"content":"Specify style and content to generate images with specific characteristics","children":[],"payload":{"lines":"940,942"}}],"payload":{"lines":"937,942"}}],"payload":{"lines":"935,936"}},{"content":"Use Azure OpenAI APIs to submit prompts and receive responses","children":[{"content":"<pre><code data-lines=\"944,956\">POST https:<span class=\"hljs-regexp\">//</span>{endpoint}<span class=\"hljs-regexp\">/openai/</span>deployments<span class=\"hljs-regexp\">/{deployment-id}/</span>completions?api-version=<span class=\"hljs-number\">2024</span>-<span class=\"hljs-number\">06</span>-<span class=\"hljs-number\">01</span>\n\n{\n <span class=\"hljs-string\">\"prompt\"</span>: [\n  <span class=\"hljs-string\">\"tell me a joke about mango\"</span>\n ],\n <span class=\"hljs-string\">\"max_tokens\"</span>: <span class=\"hljs-number\">32</span>,\n <span class=\"hljs-string\">\"temperature\"</span>: <span class=\"hljs-number\">1.0</span>,\n <span class=\"hljs-string\">\"n\"</span>: <span class=\"hljs-number\">1</span>\n}\n</code></pre>","children":[],"payload":{"lines":"944,956"}}],"payload":{"lines":"942,943"}}],"payload":{"lines":"878,879"}},{"content":"Optimize generative AI","children":[{"content":"Configure parameters to control generative behavior","children":[{"content":"Use <mark><a href=\"https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cpython-new&amp;pivots=programming-language-studio#playground\">Chat Playground</a></mark> to familiarize with model parameters to control the generative behavior, like:","children":[{"content":"<strong>Deployments</strong>: Your deployment name that is associated with a specific model.","children":[],"payload":{"lines":"962,963"}},{"content":"<strong>Temperature</strong>: Controls randomness.","children":[{"content":"Lowering the temperature means that the model produces more repetitive and deterministic responses.","children":[],"payload":{"lines":"964,965"}},{"content":"Increasing the temperature results in more unexpected or creative responses.","children":[],"payload":{"lines":"965,966"}},{"content":"Try adjusting <em>temperature</em> or <em>Top P</em> but not both.","children":[],"payload":{"lines":"966,967"}}],"payload":{"lines":"963,967"}},{"content":"<strong>Max length (tokens)</strong>: Set a limit on the number of tokens per model response.","children":[{"content":"The API supports a maximum of 4096 tokens shared between the prompt (including system message,<br>\nexamples, message history, and user query) and the model's response. One token is roughly four<br>\ncharacters for typical English text.","children":[],"payload":{"lines":"968,971"}}],"payload":{"lines":"967,971"}},{"content":"<strong>Top probabilities</strong> Similar to temperature, this controls randomness but uses a different<br>\nmethod. Lowering Top P narrows the model's token selection to likelier tokens.<br>\nIncreasing Top P lets the model choose from tokens with both high and low likelihood.","children":[{"content":"Try adjusting <em>temperature</em> or <em>Top P</em> but not both.","children":[],"payload":{"lines":"974,975"}}],"payload":{"lines":"971,975"}},{"content":"<strong>Multi-turn conversations</strong> Select the number of past messages to include in each new API<br>\nrequest. This helps give the model context for new user queries. Setting this number to<br>\n10 results in five user queries and five system responses.","children":[],"payload":{"lines":"975,978"}},{"content":"<strong>Stop sequences</strong> \tStop sequence make the model end its response at a desired point.<br>\nThe model response ends before the specified sequence, so it won't contain the stop sequence<br>\ntext. For GPT-35-Turbo, using &lt;|im_end|&gt; ensures that the model response doesn't generate a<br>\nfollow-up user query. You can include as many as four stop sequences.","children":[],"payload":{"lines":"978,983"}}],"payload":{"lines":"961,983"}}],"payload":{"lines":"959,960"}},{"content":"Apply prompt engineering techniques to improve responses","children":[{"content":"To improve generative AI responses, prompt engineering techniques can be used:","children":[{"content":"Provide clear instructions","children":[],"payload":{"lines":"986,987"}},{"content":"Primary, supporting, and grounding content","children":[],"payload":{"lines":"987,988"}},{"content":"Providing cues","children":[],"payload":{"lines":"988,989"}},{"content":"Requesting output composition: length, style, formatting, etc.","children":[],"payload":{"lines":"989,990"}},{"content":"Using system messages","children":[],"payload":{"lines":"990,991"}},{"content":"Conversation history and few-shot learning","children":[],"payload":{"lines":"991,992"}},{"content":"Chain of thought","children":[],"payload":{"lines":"992,994"}}],"payload":{"lines":"985,994"}}],"payload":{"lines":"983,984"}},{"content":"Use your own data with an Azure OpenAI model","children":[{"content":"You can use your own data with Azure OpenAI models to generate content that is specific to your<br>\norganization:","children":[{"content":"Setup a data-source: such as blob storage","children":[],"payload":{"lines":"998,999"}},{"content":"Configure studio to connect to the data-source","children":[],"payload":{"lines":"999,1000"}},{"content":"Use Azure OpenAI model per usual to generate content","children":[],"payload":{"lines":"1000,1001"}}],"payload":{"lines":"996,1001"}},{"content":"You can configure the model with specific parameters to control the generative behavior:","children":[{"content":"<strong>Strictness determines</strong> the system's aggressiveness in filtering search documents based on<br>\ntheir similarity scores.","children":[],"payload":{"lines":"1002,1004"}},{"content":"<strong>Retrieved documents</strong> is an integer that can be set to 3, 5, 10, or 20, and controls the<br>\nnumber of document chunks provided to the large language model for formulating the final response.","children":[],"payload":{"lines":"1004,1006"}},{"content":"<strong>Limit responses</strong> attempts to only rely on your documents for responses.","children":[],"payload":{"lines":"1006,1008"}}],"payload":{"lines":"1001,1008"}}],"payload":{"lines":"994,995"}},{"content":"Fine-tune an Azure OpenAI model","children":[{"content":"Fine-tuning an Azure OpenAI model allows you to customize the model to better suit your needs","children":[],"payload":{"lines":"1010,1011"}},{"content":"Fine-tuning is expensive and time-consuming, but reduces the need for many examples to<br>\nachieve good performance","children":[],"payload":{"lines":"1011,1013"}}],"payload":{"lines":"1008,1009"}}],"payload":{"lines":"957,958"}}],"payload":{"lines":"876,877"}}],"payload":{"lines":"10,11"}}]},{"colorFreezeLevel":4})</script>
</body>
</html>
