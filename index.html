<!DOCTYPE html>
<html>
<head>
<link rel="icon" type="image/png" href="favicon.png">
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<title>{{ env.MAP_TITLE }}</title>
<style>
* {
  margin: 0;
  padding: 0;
}
#mindmap {
  display: block;
  width: 100vw;
  height: 100vh;
}
</style>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@highlightjs/cdn-assets@11.8.0/styles/default.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.17.0/dist/style.css">
</head>
<body>
<svg id="mindmap"></svg>
<script src="https://cdn.jsdelivr.net/npm/d3@7.8.5/dist/d3.min.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-view@0.17.0/dist/browser/index.js"></script><script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@0.17.0/dist/index.js"></script><script>((r) => {
            setTimeout(r);
          })(() => {
  const { markmap, mm } = window;
  const toolbar = new markmap.Toolbar();
  toolbar.attach(mm);
  const el = toolbar.render();
  el.setAttribute("style", "position:absolute;bottom:20px;right:20px");
  document.body.append(el);
})</script><script>((getMarkmap, getOptions, root2, jsonOptions) => {
              const markmap = getMarkmap();
              window.mm = markmap.Markmap.create(
                "svg#mindmap",
                (getOptions || markmap.deriveOptions)(jsonOptions),
                root2
              );
            })(() => window.markmap,null,{"content":"AI-102: Azure AI Engineer Associate","children":[{"content":"AI-102 - Resources","children":[{"content":"<a href=\"https://learn.microsoft.com/en-us/certifications/exams/ai-102\">AI-102: Azure AI Engineer Associate</a>","children":[],"payload":{"lines":"2,3"}},{"content":"Course: <a href=\"https://learn.microsoft.com/en-us/training/courses/ai-102t00/\">Designing and Implementing a Microsoft Azure AI Solution</a>","children":[],"payload":{"lines":"3,4"}},{"content":"<a href=\"https://learn.microsoft.com/en-us/credentials/certifications/resources/study-guides/ai-102\">Study guide</a>","children":[],"payload":{"lines":"4,5"}},{"content":"<a href=\"https://learn.microsoft.com/en-us/credentials/certifications/azure-ai-engineer/practice/assessment?assessment-type=practice&amp;assessmentId=61&amp;practice-assessment-type=certification\">Practice assessment</a>","children":[],"payload":{"lines":"5,6"}},{"content":"<a href=\"https://learn.microsoft.com/en-us/shows/exam-readiness-zone/preparing-for-ai-102-plan-and-manage-an-azure-ai-solution\">Exam prep videos</a>","children":[],"payload":{"lines":"6,7"}},{"content":"Azure <a href=\"https://azure.github.io/aihub\">AI Hub</a>","children":[],"payload":{"lines":"7,8"}},{"content":"<a href=\"https://aka.ms/examdemo\">Exam Sandbox</a>: Experience the look and feel of the exam interface before taking it.","children":[],"payload":{"lines":"8,10"}}],"payload":{"lines":"0,1","fold":1}},{"content":"Skills at a glance","children":[{"content":"Plan and manage an Azure AI solution (15–20%)","children":[{"content":"Select the appropriate Azure AI service","children":[{"content":"Select the appropriate service for a computer vision solution","children":[{"content":"Azure AI Vision","children":[{"content":"Processes images and videos to understand their content","children":[],"payload":{"lines":"20,22"}}],"payload":{"lines":"18,19"}},{"content":"Face API","children":[{"content":"Detects and recognizes human faces","children":[],"payload":{"lines":"24,26"}}],"payload":{"lines":"22,23"}},{"content":"Azure AI Custom Vision Service","children":[{"content":"Builds and deploys custom image classification models","children":[],"payload":{"lines":"28,30"}}],"payload":{"lines":"26,27"}},{"content":"Document Intelligence","children":[{"content":"Extracts text, key-value pairs, and tables from documents","children":[],"payload":{"lines":"32,34"}}],"payload":{"lines":"30,31"}},{"content":"Azure AI Video Indexer","children":[{"content":"Extracts insights from videos and live streams","children":[],"payload":{"lines":"36,38"}}],"payload":{"lines":"34,35"}}],"payload":{"lines":"16,17"}},{"content":"Select the appropriate service for a natural language processing solution","children":[{"content":"Custom text classification","children":[],"payload":{"lines":"40,41"}},{"content":"Custom named entity recognition","children":[],"payload":{"lines":"41,42"}},{"content":"Conversational Language Understanding","children":[],"payload":{"lines":"42,43"}},{"content":"Entity Linking","children":[],"payload":{"lines":"43,44"}},{"content":"Key Phrase Extraction","children":[],"payload":{"lines":"44,45"}},{"content":"Language Detection","children":[],"payload":{"lines":"45,46"}},{"content":"Named Entity Recognition (NER)","children":[],"payload":{"lines":"46,47"}},{"content":"Orchestration workflow","children":[],"payload":{"lines":"47,48"}},{"content":"Personally identifiable information (PII) detection","children":[],"payload":{"lines":"48,49"}},{"content":"Question Answering","children":[],"payload":{"lines":"49,50"}},{"content":"Sentiment Analysis","children":[],"payload":{"lines":"50,51"}},{"content":"Summarization","children":[],"payload":{"lines":"51,52"}},{"content":"Text Analytics for Health","children":[],"payload":{"lines":"52,54"}}],"payload":{"lines":"38,39"}},{"content":"Select the appropriate service for a speech solution","children":[{"content":"Speech to Text","children":[{"content":"Supports intermediate results, end-of-speech detection, automatic text formatting, profanity<br>\nmasking, and includes real-time speech-to-text and batch transcription","children":[],"payload":{"lines":"58,61"}}],"payload":{"lines":"56,57"}},{"content":"Language identification","children":[{"content":"Identifies the spoken language in a given audio stream","children":[],"payload":{"lines":"63,65"}}],"payload":{"lines":"61,62"}},{"content":"Text-to-Speech","children":[{"content":"Converts text to natural-sounding speech","children":[],"payload":{"lines":"67,69"}}],"payload":{"lines":"65,66"}},{"content":"Speech Recognition","children":[{"content":"Identifies and verifies the people speaking based on audio","children":[],"payload":{"lines":"71,73"}}],"payload":{"lines":"69,70"}},{"content":"Pronunciation Assessment","children":[{"content":"Evaluates the pronunciation and provides feedback on the accuracy and fluency of the<br>\nspeech","children":[],"payload":{"lines":"75,78"}}],"payload":{"lines":"73,74"}},{"content":"Speech translation","children":[{"content":"Translates streaming audio in real-time and provides result as text/synthesized speech","children":[],"payload":{"lines":"80,82"}}],"payload":{"lines":"78,79"}},{"content":"Intent recognition","children":[{"content":"Derives user intents from transcribed speech and act on voice commands","children":[],"payload":{"lines":"84,86"}}],"payload":{"lines":"82,83"}}],"payload":{"lines":"54,55"}},{"content":"Select the appropriate service for a generative AI solution","children":[{"content":"<mark>TODO</mark>","children":[],"payload":{"lines":"88,90"}}],"payload":{"lines":"86,87"}},{"content":"Select the appropriate service for a document intelligence solution","children":[{"content":"Document analysis model","children":[],"payload":{"lines":"92,93"}},{"content":"Prebuilt model","children":[],"payload":{"lines":"93,94"}},{"content":"Custom model","children":[],"payload":{"lines":"94,96"}}],"payload":{"lines":"90,91"}},{"content":"Select the appropriate service for a knowledge mining solution","children":[{"content":"Azure AI Search","children":[],"payload":{"lines":"98,100"}}],"payload":{"lines":"96,97"}}],"payload":{"lines":"14,15"}},{"content":"Plan, create and deploy an Azure AI service","children":[{"content":"Plan for a solution that meets Responsible AI principles","children":[{"content":"<strong>Fairness</strong>: AI systems should treat all people fairly.","children":[{"content":"<strong>Fairlearn</strong>: An Open-source toolkit for assessing and improving the<br>\nfairness of machine learning models.","children":[],"payload":{"lines":"105,107"}}],"payload":{"lines":"104,107"}},{"content":"<strong>Reliability and safety</strong>: AI systems should perform reliably and safely.","children":[{"content":"Test the model","children":[],"payload":{"lines":"108,109"}},{"content":"Risks and harm related information should be accessible from the model users","children":[],"payload":{"lines":"109,110"}}],"payload":{"lines":"107,110"}},{"content":"<strong>Privacy and security</strong>: AI systems should respect privacy and maintain security.","children":[{"content":"Personally identifiable information (PII) should be protected","children":[],"payload":{"lines":"111,112"}}],"payload":{"lines":"110,112"}},{"content":"<strong>Inclusiveness</strong>: AI systems should empower everyone and engage people.","children":[],"payload":{"lines":"112,113"}},{"content":"<strong>Transparency</strong>: AI systems should be transparent and understandable.","children":[{"content":"<em>Interpretability/Intellegibility</em>: The ability to explain the results of a model<br>\nin a way that is understandable to humans.","children":[],"payload":{"lines":"114,116"}}],"payload":{"lines":"113,116"}},{"content":"<strong>Accountability</strong>: AI systems should be accountable to people.","children":[{"content":"<strong>Model governance</strong>: The process of managing the entire lifecycle of a model,<br>\nincluding model creation, deployment, and monitoring.","children":[],"payload":{"lines":"117,119"}},{"content":"<strong>Organizational principles</strong>: Define the roles and responsibilities of the<br>\npeople involved in the model lifecycle.","children":[],"payload":{"lines":"119,122"}}],"payload":{"lines":"116,122"}}],"payload":{"lines":"102,103"}},{"content":"Create an Azure AI resource","children":[{"content":"From the Azure portal","children":[],"payload":{"lines":"124,125"}},{"content":"Using Azure CLI","children":[],"payload":{"lines":"125,126"}},{"content":"Using client librariy","children":[],"payload":{"lines":"126,127"}},{"content":"Using ARM templates, Bicep, or Terraform","children":[],"payload":{"lines":"127,129"}}],"payload":{"lines":"122,123"}},{"content":"Determine a default endpoint for a service","children":[{"content":"Multi-service resource","children":[{"content":"Multiple Azure AI resources with a single key and endpoint","children":[],"payload":{"lines":"132,133"}},{"content":"Consolidate billing from the the services you use","children":[],"payload":{"lines":"133,134"}}],"payload":{"lines":"131,134"}},{"content":"Single-service resource","children":[{"content":"Single Azure AI resource with a single key and endpoint","children":[],"payload":{"lines":"135,136"}},{"content":"Use free tier for testing and development: only supported in single-service resources","children":[],"payload":{"lines":"136,137"}}],"payload":{"lines":"134,137"}},{"content":"Endpoint URI is one of the three primary parameters for Azure AI","children":[],"payload":{"lines":"137,138"}},{"content":"2 (access) keys are provided for each Azure AI resource by default","children":[{"content":"Protect the keys by using Azure Key Vault","children":[],"payload":{"lines":"139,140"}}],"payload":{"lines":"138,140"}},{"content":"Authenticate with:","children":[{"content":"Single or multi-service key","children":[],"payload":{"lines":"141,142"}},{"content":"Token (REST API)","children":[],"payload":{"lines":"142,143"}},{"content":"Entra ID identity","children":[],"payload":{"lines":"143,145"}}],"payload":{"lines":"140,145"}}],"payload":{"lines":"129,130"}},{"content":"Integrate Azure AI services into a continuous integration and continuous delivery (CI/CD) pipeline","children":[],"payload":{"lines":"145,146"}},{"content":"Plan and implement a container deployment","children":[{"content":"<mark>Azure Container Instances</mark> (ACI): on demand standalones containers with minimal setup in<br>\nserverless environment.","children":[],"payload":{"lines":"149,151"}},{"content":"<mark>Azure Kubernetes Service</mark> (AKS): Managed Kubernetes service for deploying, managing, and<br>\nscaling containerized applications using Kubernetes.","children":[],"payload":{"lines":"151,154"}}],"payload":{"lines":"147,148"}}],"payload":{"lines":"100,101"}},{"content":"Manage, monitor, and secure an Azure AI service","children":[{"content":"Configure diagnostic logging","children":[{"content":"Enable diagnostic logging for an Azure AI resource:","children":[{"content":"<mark>Log Analytics Workspace</mark> to analyze logs and metrics (Azure Monitor)","children":[],"payload":{"lines":"159,160"}},{"content":"<mark>Event Hub</mark> for streaming logs to other services","children":[],"payload":{"lines":"160,161"}},{"content":"<mark>Storage Account</mark> for archiving logs with less expensive storage","children":[],"payload":{"lines":"161,163"}}],"payload":{"lines":"158,163"}}],"payload":{"lines":"156,157"}},{"content":"Monitor an Azure AI resource","children":[{"content":"<em>Metrics</em>: capture regular data points about the behavior of the resource in time-series database","children":[],"payload":{"lines":"165,166"}},{"content":"<em>Alerts</em>: notify you when a metric breaches a threshold","children":[],"payload":{"lines":"166,167"}},{"content":"<em>Diagnostics settings</em>: configure the resource to send logs and metrics to a destination","children":[],"payload":{"lines":"167,168"}},{"content":"<em>Activity logs</em>: records operations made on the resource","children":[],"payload":{"lines":"168,170"}}],"payload":{"lines":"163,164"}},{"content":"Manage costs for Azure AI services","children":[{"content":"<a href=\"https://azure.microsoft.com/en-us/pricing/calculator/\">Azure Pricing Calculator</a>","children":[{"content":"Estimate the cost of Azure services","children":[],"payload":{"lines":"173,174"}}],"payload":{"lines":"172,174"}},{"content":"<a href=\"https://docs.microsoft.com/en-us/azure/cost-management-billing/costs/quick-acm-cost-analysis?tabs=cost-analysis\">Azure Cost Management and Billing</a>","children":[{"content":"Monitor and analyze costs","children":[],"payload":{"lines":"175,176"}},{"content":"Create budgets and alerts","children":[],"payload":{"lines":"176,177"}},{"content":"Optimize costs","children":[],"payload":{"lines":"177,178"}},{"content":"Billing administrative tasks","children":[],"payload":{"lines":"178,180"}}],"payload":{"lines":"174,180"}}],"payload":{"lines":"170,171"}},{"content":"Manage account keys","children":[{"content":"<mark>TODO</mark>","children":[],"payload":{"lines":"182,184"}}],"payload":{"lines":"180,181"}},{"content":"Protect account keys by using Azure Key Vault","children":[{"content":"<mark>TODO</mark>","children":[],"payload":{"lines":"186,188"}}],"payload":{"lines":"184,185"}},{"content":"Manage authentication for an Azure AI Service resource","children":[{"content":"<mark>TODO</mark>","children":[],"payload":{"lines":"190,192"}}],"payload":{"lines":"188,189"}},{"content":"Manage private communications","children":[{"content":"<mark>TODO</mark>","children":[],"payload":{"lines":"194,196"}}],"payload":{"lines":"192,193"}}],"payload":{"lines":"154,155"}}],"payload":{"lines":"12,13"}},{"content":"Implement content moderation solutions (10–15%)","children":[{"content":"Create solutions for content delivery","children":[{"content":"Implement a text moderation solution with Azure AI Content Safety","children":[{"content":"\n<p data-lines=\"202,203\">Detect and filter harmful or inappropriate text content in applications</p>","children":[{"content":"","children":[{"content":"Get an API endpoint + subscription key","children":[],"payload":{"lines":"204,205"}},{"content":"Send a request to the endpoint with the subscription key and the text to analyze","children":[],"payload":{"lines":"205,206"}},{"content":"Get a response with the classification of the text as JSON","children":[],"payload":{"lines":"206,208"}}],"payload":{"lines":"204,208"}},{"content":"","children":[{"content":"Harm categories (e.g. hate and fairness, sexual, violence, self-harm)","children":[],"payload":{"lines":"208,209"}},{"content":"Severity level from 0 to 7 (e.g. safe, low, medium, high)","children":[],"payload":{"lines":"209,211"}}],"payload":{"lines":"208,211"}}],"payload":{"lines":"202,211"}}],"payload":{"lines":"200,201"}},{"content":"Implement an image moderation solution with Azure AI Content Safety","children":[{"content":"\n<p data-lines=\"213,214\">Detect and filter harmful or inappropriate images in applications</p>","children":[{"content":"","children":[{"content":"Get an API endpoint + subscription key","children":[],"payload":{"lines":"215,216"}},{"content":"Send a request to the endpoint with the subscription key and the image to analyze","children":[],"payload":{"lines":"216,217"}},{"content":"Get a response with the classification of the image as JSON","children":[],"payload":{"lines":"217,219"}}],"payload":{"lines":"215,219"}},{"content":"","children":[{"content":"Harm categories (e.g. hate and fairness, sexual, violence, self-harm)","children":[],"payload":{"lines":"219,220"}},{"content":"Severity level from 0 to 7 (e.g. safe, low, medium, high)","children":[],"payload":{"lines":"220,222"}}],"payload":{"lines":"219,222"}}],"payload":{"lines":"213,222"}}],"payload":{"lines":"211,212"}}],"payload":{"lines":"198,199"}}],"payload":{"lines":"196,197"}},{"content":"Implement computer vision solutions (15–20%)","children":[{"content":"Analyze images","children":[{"content":"Select visual features to meet image processing requirements","children":[{"content":"Create Azure AI custom vision training and prediction resources.","children":[],"payload":{"lines":"228,230"}}],"payload":{"lines":"226,227"}},{"content":"Detect objects in images and generate image tags","children":[],"payload":{"lines":"230,231"}},{"content":"Include image analysis features in an image processing request","children":[],"payload":{"lines":"234,235"}},{"content":"Interpret image processing responses","children":[{"content":"<mark>TODO</mark>","children":[],"payload":{"lines":"240,242"}}],"payload":{"lines":"238,239"}},{"content":"Extract text from images using Azure AI Vision","children":[{"content":"Azure AI vision can extract text from images and handwritten text","children":[{"content":"<mark><a href=\"https://learn.microsoft.com/en-us/azure/ai-services/computer-vision/concept-ocr\">OCR for images (version 4.0)</a></mark>","children":[{"content":"<strong>Inputs</strong>: Images: General, in-the-wild images","children":[],"payload":{"lines":"246,247"}},{"content":"<strong>Examples</strong>: labels, street signs, and posters","children":[],"payload":{"lines":"247,248"}},{"content":"Optimized for general, non-document images with a performance-enhanced <strong>synchronous API</strong><br>\nthat makes it easier to embed OCR in your user experience scenarios.","children":[],"payload":{"lines":"248,250"}}],"payload":{"lines":"245,250"}},{"content":"<mark><a href=\"https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/concept-read\">Document Intelligence read model</a></mark>","children":[{"content":"<strong>Inputs</strong>:Documents: Digital and scanned, including images","children":[],"payload":{"lines":"251,252"}},{"content":"<strong>Examples</strong>: books, articles, and reports","children":[],"payload":{"lines":"252,253"}},{"content":"Optimized for text-heavy scanned and digital documents with an <strong>asynchronous API</strong> to help<br>\nautomate intelligent document processing at scale.","children":[],"payload":{"lines":"253,256"}}],"payload":{"lines":"250,256"}}],"payload":{"lines":"244,256"}}],"payload":{"lines":"242,243"}},{"content":"Convert handwritten text using Azure AI Vision","children":[{"content":"<mark>TODO</mark>","children":[],"payload":{"lines":"258,260"}}],"payload":{"lines":"256,257"}}],"payload":{"lines":"224,225"}},{"content":"Implement custom computer vision models by using Azure AI Vision","children":[{"content":"Choose between image classification and object detection models","children":[{"content":"<strong>Image classification</strong>: Classify or assign a label to an image","children":[],"payload":{"lines":"264,265"}},{"content":"<strong>Object detection</strong>: Identify and locate objects in an image","children":[],"payload":{"lines":"265,266"}},{"content":"You can upload and tag your images to train the classifier or detector model.","children":[],"payload":{"lines":"266,267"}},{"content":"For both image classification and object detection, you need to:","children":[{"content":"Create a new project","children":[],"payload":{"lines":"268,269"}},{"content":"Name and describe it","children":[],"payload":{"lines":"269,270"}},{"content":"Select a project type: Classification or Object Detection","children":[],"payload":{"lines":"270,271"}},{"content":"Select an available domain (General, Food, Landmarks, Retail, Logo etc.)","children":[],"payload":{"lines":"271,272"}},{"content":"Train and test the model","children":[],"payload":{"lines":"272,273"}},{"content":"Publish and consume the model","children":[],"payload":{"lines":"273,275"}}],"payload":{"lines":"267,275"}}],"payload":{"lines":"262,263"}},{"content":"Label images","children":[{"content":"For image classification you need to select either:","children":[{"content":"Multilabel classification: Assign multiple labels to an image","children":[],"payload":{"lines":"278,279"}},{"content":"Multiclass classification: Assign a single label to an image","children":[],"payload":{"lines":"279,281"}}],"payload":{"lines":"277,281"}}],"payload":{"lines":"275,276"}},{"content":"Train a custom image model, including image classification and object detection","children":[{"content":"Select <code>train</code> button to start training the model","children":[],"payload":{"lines":"283,284"}},{"content":"The training process can take a few minutes to a few hours","children":[],"payload":{"lines":"284,285"}},{"content":"Monitor the training process and check the metrics via the performance tab","children":[],"payload":{"lines":"285,286"}},{"content":"Delete obsolete iterations","children":[],"payload":{"lines":"286,288"}}],"payload":{"lines":"281,282"}},{"content":"Evaluate custom vision model metrics","children":[{"content":"Available metrics:","children":[{"content":"<strong>Precision</strong>","children":[{"content":"A percentage value that indicates the proportion of true positive predictions in the<br>\ntotal number of positive predictions.","children":[],"payload":{"lines":"292,294"}}],"payload":{"lines":"291,294"}},{"content":"<strong>Recall</strong>","children":[{"content":"A percentage value that indicates the proportion of true positive predictions in the<br>\ntotal number of actual positive instances.","children":[],"payload":{"lines":"295,297"}}],"payload":{"lines":"294,297"}},{"content":"<strong>mAP</strong> (mean Average Precision) - Object Detection only","children":[{"content":"A metric that evaluates the precision-recall curve for object detection models.","children":[],"payload":{"lines":"298,299"}}],"payload":{"lines":"297,299"}}],"payload":{"lines":"290,299"}},{"content":"Additional metrics:","children":[{"content":"<strong>Probability threshold</strong>: The level of confidence that a prediction needs to have in order<br>\nto be considered correct (for the purposes of calculating precision and recall)","children":[],"payload":{"lines":"300,302"}},{"content":"<strong>Overlapping threshold</strong>: Sets the minimum allowed overlap between the predicted object's<br>\nbounding box and the actual user-entered bounding box. If the bounding boxes don't overlap to<br>\nthis degree, the prediction won't be considered correct.","children":[],"payload":{"lines":"302,306"}}],"payload":{"lines":"299,306"}}],"payload":{"lines":"288,289"}},{"content":"Publish a custom vision model","children":[{"content":"Make your model available for consumption by others by publishing it.","children":[{"content":"Select the Publish <code>✓</code> button","children":[],"payload":{"lines":"309,310"}},{"content":"Provide the model name and prediction resource","children":[],"payload":{"lines":"310,311"}},{"content":"Select the <code>Publish</code> button","children":[],"payload":{"lines":"311,313"}}],"payload":{"lines":"308,313"}}],"payload":{"lines":"306,307"}},{"content":"Consume a custom vision model","children":[{"content":"<mark>TODO</mark>","children":[],"payload":{"lines":"315,317"}}],"payload":{"lines":"313,314"}}],"payload":{"lines":"260,261"}},{"content":"Analyze videos","children":[{"content":"Use Azure AI Video Indexer to extract insights from a video or live stream","children":[{"content":"Analyze video content to extract topics, labels, named-entities, emotions, and scenes.","children":[],"payload":{"lines":"321,322"}},{"content":"A timeline is provided to navigate through the video content along with the dialogue and<br>\nspeaker identification.","children":[],"payload":{"lines":"322,325"}}],"payload":{"lines":"319,320"}},{"content":"Use Azure AI Vision Spatial Analysis to detect presence and movement of people in video","children":[{"content":"People counting","children":[],"payload":{"lines":"327,328"}},{"content":"Entrance and exit counting","children":[],"payload":{"lines":"328,329"}},{"content":"Social distancing and face/mask detection","children":[],"payload":{"lines":"329,331"}}],"payload":{"lines":"325,326"}}],"payload":{"lines":"317,318"}}],"payload":{"lines":"222,223"}},{"content":"Implement natural language processing solutions (30–35%)","children":[{"content":"Analyze text by using Azure AI Language","children":[{"content":"Extract key phrases","children":[{"content":"Identify the main points in a text","children":[{"content":"Create an Azure AI language resource","children":[],"payload":{"lines":"338,339"}},{"content":"Get the endpoint and subscription key","children":[],"payload":{"lines":"339,340"}},{"content":"Send a request to the endpoint with the subscription key and the raw text to analyze","children":[],"payload":{"lines":"340,341"}},{"content":"Get a response with the key phrases as JSON: stream or store locally.","children":[],"payload":{"lines":"341,342"}}],"payload":{"lines":"337,342"}},{"content":"3 consumption ways:","children":[{"content":"Language Studio","children":[],"payload":{"lines":"343,344"}},{"content":"REST API","children":[],"payload":{"lines":"344,345"}},{"content":"Docker container","children":[],"payload":{"lines":"345,347"}}],"payload":{"lines":"342,347"}}],"payload":{"lines":"335,336"}},{"content":"Extract entities","children":[{"content":"Entity linking: identify and disambiguate entities in text.","children":[{"content":"Different endpoint for entity linking.","children":[],"payload":{"lines":"350,351"}}],"payload":{"lines":"349,351"}},{"content":"Named entity recognition: identify and classify named entities in text.","children":[{"content":"Ex: person, location, organization, date, etc.","children":[],"payload":{"lines":"352,354"}}],"payload":{"lines":"351,354"}}],"payload":{"lines":"347,348"}},{"content":"Determine sentiment of text","children":[{"content":"<a href=\"https://learn.microsoft.com/en-us/azure/ai-services/language-service/sentiment-opinion-mining/overview?tabs=prebuilt\">Evaluate text and returns sentiment scores and labels for each sentence</a>","children":[{"content":"<strong>Sentiment analysis</strong>: Provides sentiment labels (such as \"negative\", \"neutral\" and<br>\n\"positive\") based on the highest confidence score found by the service at a sentence and<br>\ndocument-level.","children":[{"content":"This feature also returns confidence scores between 0 and 1 for each document &amp; sentences<br>\nwithin it for positive, neutral and negative sentiment.","children":[],"payload":{"lines":"360,362"}}],"payload":{"lines":"357,362"}},{"content":"<strong>Opinion mining</strong>: Also known as aspect-based sentiment analysis in Natural Language Processing<br>\n(NLP).","children":[{"content":"this feature provides more granular information about the opinions related to words<br>\n(such as the attributes of products or services) in text.","children":[],"payload":{"lines":"364,367"}}],"payload":{"lines":"362,367"}}],"payload":{"lines":"356,367"}}],"payload":{"lines":"354,355"}},{"content":"Detect the language used in text","children":[{"content":"Evaluates a text and returns scored language identifiers.","children":[{"content":"Large panel of languages supported including regional dialects.","children":[],"payload":{"lines":"370,371"}},{"content":"In case of mixed languages, the service will return the most used language with a low<br>\nconfidence score","children":[],"payload":{"lines":"371,374"}}],"payload":{"lines":"369,374"}}],"payload":{"lines":"367,368"}},{"content":"Detect personally identifiable information (PII) in text","children":[{"content":"Identify, categorize and redact sensitive information in unstructured text.","children":[{"content":"Create an Azure AI language resource","children":[],"payload":{"lines":"377,378"}},{"content":"Get the endpoint and subscription key","children":[],"payload":{"lines":"378,379"}},{"content":"Send a request to the endpoint with the subscription key and the raw text to analyze","children":[],"payload":{"lines":"379,380"}},{"content":"Get a response with the key phrases as JSON: stream or store locally.","children":[],"payload":{"lines":"380,381"}}],"payload":{"lines":"376,381"}},{"content":"API is stateless in synchronous mode and available for 24h in asynchronous mode.","children":[],"payload":{"lines":"381,383"}}],"payload":{"lines":"374,375"}}],"payload":{"lines":"333,334"}},{"content":"Process speech by using Azure AI Speech","children":[{"content":"Implement text-to-speech","children":[{"content":"Life-like speech synthesis (fluid and natural-sounding)","children":[],"payload":{"lines":"387,388"}},{"content":"Customizable voices","children":[],"payload":{"lines":"388,389"}},{"content":"Fined-grained audio controls (rate, pitch, pause, pronunciation etc.)","children":[],"payload":{"lines":"389,390"}},{"content":"Flexible deployment (cloud or containers)","children":[],"payload":{"lines":"390,392"}}],"payload":{"lines":"385,386"}},{"content":"Implement speech-to-text","children":[{"content":"Real-time transcription of audio streams into written text by using SSML<br>\n(Speech Synthesis Markup Language).","children":[{"content":"High quality transcription","children":[],"payload":{"lines":"396,397"}},{"content":"Flexible deployment","children":[],"payload":{"lines":"397,398"}},{"content":"Customizable models","children":[],"payload":{"lines":"398,399"}},{"content":"Production-ready","children":[],"payload":{"lines":"399,401"}}],"payload":{"lines":"394,401"}}],"payload":{"lines":"392,393"}},{"content":"Improve text-to-speech by using Speech Synthesis Markup Language (SSML)","children":[{"content":"SSML can be used to fine-tune text-to-speech models outputs.","children":[{"content":"SSML is a markup language that allows developers to control various aspects of speech<br>\nsynthesis, such as pronunciation, volume, pitch, rate, and more.","children":[],"payload":{"lines":"404,406"}}],"payload":{"lines":"403,406"}},{"content":"Custom neural voice (CNV) models can be used to create custom voices for text-to-speech<br>\napplications.","children":[{"content":"CNV models are trained on a speaker's voice data to create a custom voice that can be used<br>\nin text-to-speech applications.","children":[],"payload":{"lines":"408,411"}}],"payload":{"lines":"406,411"}}],"payload":{"lines":"401,402"}},{"content":"Implement custom speech solutions","children":[{"content":"Test custom speech solutions for Word Error Rate (WER) with accuracy testing and custom acoustic<br>\nmodels:","children":[{"content":"Needs improvement: &gt;30%","children":[],"payload":{"lines":"415,416"}},{"content":"Acceptable: ~20%","children":[],"payload":{"lines":"416,417"}},{"content":"Ready for production: &lt;10%","children":[],"payload":{"lines":"417,419"}}],"payload":{"lines":"413,419"}}],"payload":{"lines":"411,412"}},{"content":"Implement intent recognition","children":[{"content":"2 methods:","children":[{"content":"Pattern matching: for offline solutions","children":[{"content":"Create code and speech configuration","children":[],"payload":{"lines":"425,426"}},{"content":"Initialize the intent recognizer and declare entities as intent","children":[],"payload":{"lines":"426,427"}},{"content":"Enable recognition of intent","children":[],"payload":{"lines":"427,428"}},{"content":"Instruct code to stop on intent recognition","children":[],"payload":{"lines":"428,429"}},{"content":"Display results","children":[],"payload":{"lines":"429,430"}},{"content":"Publish","children":[],"payload":{"lines":"430,431"}}],"payload":{"lines":"424,431"}},{"content":"CLU (Conversational Language Understanding): prediction of intents","children":[{"content":"Create a new project by importing a JSON file","children":[],"payload":{"lines":"432,433"}},{"content":"Train model","children":[],"payload":{"lines":"433,434"}},{"content":"Choose training mode and data splitting","children":[],"payload":{"lines":"434,435"}},{"content":"Deploy model","children":[],"payload":{"lines":"435,436"}},{"content":"Use model to recognize intents from an audio stream","children":[],"payload":{"lines":"436,438"}}],"payload":{"lines":"431,438"}}],"payload":{"lines":"423,438"}}],"payload":{"lines":"419,420"}},{"content":"Implement keyword recognition","children":[{"content":"\n<p data-lines=\"440,441\">Detect word or short phrase within audio stream or content</p>","children":[{"content":"","children":[{"content":"Create a new project in speech studio","children":[],"payload":{"lines":"442,443"}},{"content":"Create a custom keyword:","children":[],"payload":{"lines":"443,444"}},{"content":"Create new model","children":[],"payload":{"lines":"444,445"}},{"content":"Provide name/description and the keyword","children":[],"payload":{"lines":"445,446"}},{"content":"Validate","children":[],"payload":{"lines":"446,447"}},{"content":"Select a model type and Create","children":[],"payload":{"lines":"447,449"}}],"payload":{"lines":"442,449"}},{"content":"","children":[{"content":"<strong>Basic</strong>: rapid prototyping","children":[],"payload":{"lines":"449,450"}},{"content":"<strong>Advanced</strong>: improved accuracy characteristics for product integration","children":[],"payload":{"lines":"450,452"}}],"payload":{"lines":"449,452"}},{"content":"","children":[{"content":"Select <strong>Tune</strong> to download the model","children":[],"payload":{"lines":"452,453"}},{"content":"This model can now be used","children":[],"payload":{"lines":"453,455"}}],"payload":{"lines":"452,455"}}],"payload":{"lines":"440,455"}}],"payload":{"lines":"438,439"}}],"payload":{"lines":"383,384"}},{"content":"Translate language","children":[{"content":"Resources","children":[{"content":"<a href=\"https://learn.microsoft.com/en-us/azure/ai-services/translator/\">Azure AI Translator documentation</a>","children":[],"payload":{"lines":"459,460"}},{"content":"<a href=\"https://github.com/retkowsky/azure-ai-translator\">Azure AI Translator demos</a>","children":[],"payload":{"lines":"460,462"}}],"payload":{"lines":"457,458","fold":1}},{"content":"Translate text and documents by using the Azure AI Translator service","children":[{"content":"2 distinct types of endpoints enable:","children":[{"content":"<strong>Text translation</strong>: Translate text between languages (real-time)","children":[{"content":"REST API cloud-based translator","children":[],"payload":{"lines":"466,467"}},{"content":"Docker container based translator","children":[],"payload":{"lines":"467,468"}},{"content":"Supported methods:","children":[{"content":"<strong>Languages</strong>: Returns a list of languages supported by Translate, Transliterate, and Dictionary<br>\nLookup operations. This request doesn't require authentication; just copy and paste the<br>\nfollowing GET request into your favorite REST API tool or browser:","children":[{"content":"<code>https://api.cognitive.microsofttranslator.com/languages?api-version=3.0</code>","children":[],"payload":{"lines":"472,473"}}],"payload":{"lines":"469,473"}},{"content":"<strong>Translate</strong>: Renders single source-language text to multiple target-language texts with a<br>\nsingle request.","children":[],"payload":{"lines":"473,475"}},{"content":"<strong>Transliterate</strong>: Converts characters or letters of a source language to the corresponding<br>\ncharacters or letters of a target language.","children":[],"payload":{"lines":"475,477"}},{"content":"<strong>Detect</strong>: Returns the source code language code and a boolean variable denoting whether the<br>\ndetected language is supported for text translation and transliteration.","children":[],"payload":{"lines":"477,479"}},{"content":"<strong>Dictionary lookup</strong>: Returns equivalent words for the source term in the target language.","children":[],"payload":{"lines":"479,480"}},{"content":"<strong>Dictionary example</strong>: Returns grammatical structure and context examples for the source<br>\nterm and target term pair.","children":[],"payload":{"lines":"480,482"}}],"payload":{"lines":"468,482"}}],"payload":{"lines":"465,482"}},{"content":"<strong>Document translation</strong>: Translate documents between languages (asynchronous)","children":[{"content":"REST API cloud-based translator","children":[],"payload":{"lines":"483,484"}},{"content":"Client library SDK","children":[],"payload":{"lines":"484,485"}},{"content":"Supported methods:","children":[{"content":"<strong>Translate large files</strong>: Translate whole documents asynchronously.","children":[],"payload":{"lines":"486,487"}},{"content":"<strong>Translate numerous files</strong>: Translate multiple files across all supported languages and<br>\ndialects while preserving document structure and data format.","children":[],"payload":{"lines":"487,489"}},{"content":"<strong>Preserve source file presentation</strong>: Translate files while preserving the original layout<br>\nand format.","children":[],"payload":{"lines":"489,491"}},{"content":"<strong>Apply custom translation</strong>: Translate documents using general and custom translation models.","children":[],"payload":{"lines":"491,492"}},{"content":"<strong>Apply custom glossaries</strong>: Translate documents using custom glossaries.","children":[],"payload":{"lines":"492,493"}},{"content":"<strong>Automatically detect document language</strong>: Let the Document Translation service determine<br>\nthe language of the document.","children":[],"payload":{"lines":"493,495"}},{"content":"<strong>Translate documents with content in multiple languages</strong>: Use the autodetect feature to<br>\ntranslate documents with content in multiple languages into your target language.","children":[],"payload":{"lines":"495,498"}}],"payload":{"lines":"485,498"}}],"payload":{"lines":"482,498"}}],"payload":{"lines":"464,498"}}],"payload":{"lines":"462,463"}},{"content":"Implement custom translation, including training, improving, and publishing a custom model","children":[{"content":"Train a custom model:","children":[{"content":"Select <strong>train</strong> model, enter sample data and select <strong>full training</strong>","children":[],"payload":{"lines":"501,502"}},{"content":"Select sample-source language, target language and review training costs","children":[],"payload":{"lines":"502,503"}},{"content":"Select <strong>Train now</strong> then <strong>Train</strong> to start training","children":[],"payload":{"lines":"503,504"}},{"content":"Once trained, select <strong>Model details</strong> to review the model","children":[],"payload":{"lines":"504,505"}}],"payload":{"lines":"500,505"}},{"content":"Test and publish a custom model","children":[{"content":"Select <strong>Test model</strong>, enter sample data","children":[],"payload":{"lines":"506,507"}},{"content":"Test (human evaluation) the translation","children":[],"payload":{"lines":"507,508"}},{"content":"Select <strong>Publish model</strong> to make the model available","children":[],"payload":{"lines":"508,509"}},{"content":"Select a region and validate.","children":[],"payload":{"lines":"509,511"}}],"payload":{"lines":"505,511"}}],"payload":{"lines":"498,499"}},{"content":"Translate speech-to-speech by using the Azure AI Speech service","children":[{"content":"Speech-to-speech service can translate an audio stream/input to another language as an audio output.","children":[{"content":"Works in real-time.","children":[],"payload":{"lines":"514,516"}}],"payload":{"lines":"513,516"}}],"payload":{"lines":"511,512"}},{"content":"Translate speech-to-text by using the Azure AI Speech service","children":[{"content":"4 translation services for Speech-to-text:","children":[{"content":"<mark>Speech translator API</mark>","children":[{"content":"Typically used for real-time translation of spoken languages","children":[],"payload":{"lines":"520,521"}}],"payload":{"lines":"519,521"}},{"content":"<mark>Speech CLI</mark>","children":[{"content":"Experiment with minimal code solution","children":[],"payload":{"lines":"522,523"}}],"payload":{"lines":"521,523"}},{"content":"<mark>Speech SDK</mark>","children":[{"content":"Use in your own applications","children":[],"payload":{"lines":"524,525"}}],"payload":{"lines":"523,525"}},{"content":"<mark>Speech Studio</mark>","children":[{"content":"Typically used to test and tune speech services","children":[],"payload":{"lines":"526,528"}}],"payload":{"lines":"525,528"}}],"payload":{"lines":"518,528"}}],"payload":{"lines":"516,517"}},{"content":"Translate to multiple languages simultaneously","children":[],"payload":{"lines":"528,529"}}],"payload":{"lines":"455,456"}},{"content":"Implement and manage a language understanding model by using Azure AI Language","children":[{"content":"Create intents and add utterances","children":[{"content":"<strong>Intent</strong>: action or goal expressed in a user's utterance","children":[],"payload":{"lines":"534,535"}},{"content":"<strong>Utterance</strong>: spoken or written phrases","children":[],"payload":{"lines":"535,537"}}],"payload":{"lines":"532,533"}},{"content":"Create entities","children":[{"content":"Word or phrase within utterances that can be identified and extracted","children":[{"content":"<strong>Learned component</strong>: enables predictions based on context learned while labelling of utterances","children":[],"payload":{"lines":"540,541"}},{"content":"<strong>List component</strong>: Fixed ser of related words with their synonyms","children":[],"payload":{"lines":"541,542"}},{"content":"<strong>Prebuilt component</strong>: Built-in entities like date, time, number, etc.","children":[],"payload":{"lines":"542,543"}},{"content":"<strong>Regex component</strong>: Regular expression to match entities","children":[],"payload":{"lines":"543,544"}}],"payload":{"lines":"539,544"}},{"content":"To create entities:","children":[{"content":"Navigate to <strong>Entities</strong> pivot","children":[],"payload":{"lines":"545,546"}},{"content":"Select <strong>Add</strong> and type entity name","children":[],"payload":{"lines":"546,547"}},{"content":"Define composition settings","children":[],"payload":{"lines":"547,548"}},{"content":"Attach a <em>Learned</em>, <em>Prebuilt</em> or <em>List</em> component","children":[],"payload":{"lines":"548,550"}}],"payload":{"lines":"544,550"}}],"payload":{"lines":"537,538"}},{"content":"Train, evaluate, deploy, and test a language understanding model","children":[{"content":"CLU can be used to build a custom <em>natural language understanding model</em> which predicts intention and extract information of utterances.","children":[],"payload":{"lines":"552,553"}},{"content":"Creation process:","children":[{"content":"Select data and define schema","children":[],"payload":{"lines":"554,555"}},{"content":"Label data","children":[],"payload":{"lines":"555,556"}},{"content":"Train model","children":[],"payload":{"lines":"556,557"}},{"content":"View model performance results","children":[],"payload":{"lines":"557,558"}},{"content":"Tune the model","children":[],"payload":{"lines":"558,559"}},{"content":"Deploy","children":[],"payload":{"lines":"559,560"}},{"content":"Predict intents and entities","children":[],"payload":{"lines":"560,562"}}],"payload":{"lines":"553,562"}}],"payload":{"lines":"550,551"}},{"content":"Optimize a language understanding model","children":[{"content":"Ensure training data set is representative and sufficient","children":[{"content":"Insufficient data can lead to overfitting and lower accuracy","children":[],"payload":{"lines":"565,566"}},{"content":"Adding more labeled data can improve the accuracy of the model","children":[],"payload":{"lines":"566,567"}}],"payload":{"lines":"564,567"}},{"content":"Ensure all entities are covered in test data","children":[{"content":"Absence of labeled instance can reduce accuracy of model evaluation","children":[],"payload":{"lines":"568,569"}},{"content":"Ensure all entities are covered in the test data","children":[],"payload":{"lines":"569,570"}}],"payload":{"lines":"567,570"}},{"content":"Fix unclear or ambiguous distinction between intents and entities","children":[{"content":"Similar data for different intents can lead to confusion","children":[],"payload":{"lines":"571,572"}},{"content":"You can solve this by merging similar entities or adding more examples","children":[],"payload":{"lines":"572,574"}}],"payload":{"lines":"570,574"}}],"payload":{"lines":"562,563"}},{"content":"Consume a language model from a client application","children":[{"content":"Azure AI language models can be consumed from a client application using the REST API or SDKs.","children":[{"content":"This enables users to use natural language as input to interact with the application.","children":[],"payload":{"lines":"577,578"}},{"content":"User's intent and entities are extracted and processed by the model to provide the desired output.","children":[],"payload":{"lines":"578,579"}},{"content":"Application performs the necessary actions.","children":[],"payload":{"lines":"579,581"}}],"payload":{"lines":"576,581"}}],"payload":{"lines":"574,575"}},{"content":"Backup and recover language understanding models","children":[{"content":"Export replicas of language understanding models to backup and recover them in case of data loss.","children":[{"content":"Export","children":[{"content":"Create a <code>POST</code> request with <code>Ocp-Apim-Subscription-Key</code> to create export task","children":[],"payload":{"lines":"585,586"}},{"content":"Use <code>GET</code> request to get a status of the export task","children":[],"payload":{"lines":"586,587"}},{"content":"Use <code>GET</code> request to download the exported model","children":[],"payload":{"lines":"587,588"}}],"payload":{"lines":"584,588"}},{"content":"Import","children":[{"content":"Create a <code>POST</code> request with <code>Ocp-Apim-Subscription-Key</code> to create import task","children":[{"content":"Body should contain the exported model as JSON","children":[],"payload":{"lines":"590,591"}}],"payload":{"lines":"589,591"}},{"content":"Use <code>GET</code> request to get a status of the import task","children":[],"payload":{"lines":"591,592"}},{"content":"Wait for successful completion of the task","children":[],"payload":{"lines":"592,595"}}],"payload":{"lines":"588,595"}}],"payload":{"lines":"583,595"}}],"payload":{"lines":"581,582"}}],"payload":{"lines":"530,531"}},{"content":"Create a custom question answering solution by using Azure AI Language","children":[{"content":"Create a custom question answering project","children":[{"content":"Enable custom question answering","children":[],"payload":{"lines":"599,600"}},{"content":"Create a new project with a name and a language","children":[],"payload":{"lines":"600,601"}},{"content":"Add question-answer pairs from source URLs or manually","children":[],"payload":{"lines":"601,603"}}],"payload":{"lines":"597,598"}},{"content":"Add question-and-answer pairs manually","children":[{"content":"In this case, you need to type the question and the answer manually.","children":[],"payload":{"lines":"605,607"}}],"payload":{"lines":"603,604"}},{"content":"Import sources","children":[{"content":"Use different sources to populate Azure Question Answering project:","children":[{"content":"Structured documents (manuals, guidelines, etc.)","children":[{"content":"Questions will be derived from the headings and subheadings of the document","children":[],"payload":{"lines":"611,612"}},{"content":"Answers will be derived from the subsequent text","children":[],"payload":{"lines":"612,613"}}],"payload":{"lines":"610,613"}},{"content":"Unstructured documents (articles, blogs, etc.)","children":[],"payload":{"lines":"613,614"}},{"content":"Question-and-answer documents (FAQs, etc.)","children":[{"content":"<code>.docx</code>, <code>.pdf</code>, <code>.txt</code>, <code>.html</code>, <code>.tsv</code>, <code>.csv</code>...","children":[],"payload":{"lines":"615,617"}}],"payload":{"lines":"614,617"}}],"payload":{"lines":"609,617"}}],"payload":{"lines":"607,608"}},{"content":"Train, test and publish a knowledge base","children":[{"content":"In the knowledge base, source documents are imported as Questions. You can amend the questions<br>\nand answers as needed.","children":[],"payload":{"lines":"619,621"}},{"content":"Select <strong>Save and train</strong>, then <strong>Test</strong>","children":[],"payload":{"lines":"621,622"}},{"content":"A test version of the knowledge base is created and you can analyze it with the <strong>Inspect</strong> button","children":[],"payload":{"lines":"622,623"}},{"content":"You can <strong>Publish</strong> the knowledge base to make it available for consumption through REST endpoint","children":[],"payload":{"lines":"623,625"}}],"payload":{"lines":"617,618"}},{"content":"Create a multi-turn conversation","children":[{"content":"Multi-turn conversations are dialogues between a user and a bot that require multiple steps to<br>\ncomplete.","children":[],"payload":{"lines":"627,629"}},{"content":"To create:","children":[{"content":"Select <strong>Add follow-up prompts</strong> in the knowledge base","children":[],"payload":{"lines":"630,631"}},{"content":"Fill details of the prompt","children":[],"payload":{"lines":"631,632"}},{"content":"<strong>Create link to new pair</strong>","children":[],"payload":{"lines":"632,633"}},{"content":"<strong>Save</strong>","children":[],"payload":{"lines":"633,634"}}],"payload":{"lines":"629,634"}},{"content":"Multiple follow-up prompts can be added to a single question by repeating the same process.","children":[],"payload":{"lines":"634,636"}}],"payload":{"lines":"625,626"}},{"content":"Add alternate phrasing","children":[{"content":"Add alternate questions with differences in the sentence structure or wording to improve the<br>\naccuracy of the model.","children":[],"payload":{"lines":"638,641"}}],"payload":{"lines":"636,637"}},{"content":"Add chit-chat to a knowledge base","children":[{"content":"Chit-chat is a feature that allows the bot to engage in casual conversation with the user.","children":[{"content":"Provide bot the ability to answer question in a way that fits your brand","children":[],"payload":{"lines":"644,645"}},{"content":"Set a personality for the bot","children":[],"payload":{"lines":"645,646"}},{"content":"Automatically add simple question-answer pairs to the knowledge base","children":[],"payload":{"lines":"646,648"}}],"payload":{"lines":"643,648"}}],"payload":{"lines":"641,642"}},{"content":"Export a knowledge base","children":[{"content":"Exporting a knowledge base allows you to save a copy of the knowledge base for:","children":[{"content":"Backup purpose","children":[],"payload":{"lines":"651,652"}},{"content":"CI/CD integration","children":[],"payload":{"lines":"652,653"}},{"content":"Deployment region mobility","children":[],"payload":{"lines":"653,654"}}],"payload":{"lines":"650,654"}},{"content":"Steps:","children":[{"content":"Open the <em>custom question answering</em> project","children":[],"payload":{"lines":"655,656"}},{"content":"Select <strong>Export</strong>","children":[],"payload":{"lines":"656,657"}},{"content":"Select the export format (<code>.xlsx</code> or <code>.tsv</code>) that will be exported in a <code>.zip</code> file","children":[],"payload":{"lines":"657,659"}}],"payload":{"lines":"654,659"}}],"payload":{"lines":"648,649"}},{"content":"Create a multi-language question answering solution","children":[{"content":"Multi-language question answering solutions can be created by training the model with data in<br>\nmultiple languages.","children":[{"content":"The model can be trained with data in multiple languages to support multi-language question<br>\nanswering solutions.","children":[],"payload":{"lines":"663,665"}}],"payload":{"lines":"661,665"}},{"content":"Steps:","children":[{"content":"When creating the new <em>custom question answering</em> project:","children":[],"payload":{"lines":"666,667"}},{"content":"\n<blockquote data-lines=\"667,668\">\n<p data-lines=\"667,668\"><em>I want to select the language when I create a project in this resource</em></p>\n</blockquote>","children":[],"payload":{"lines":"667,668"}},{"content":"Enter basic information and create the project","children":[],"payload":{"lines":"668,669"}},{"content":"Add sources to deploy the project","children":[],"payload":{"lines":"669,671"}}],"payload":{"lines":"665,671"}}],"payload":{"lines":"659,660"}}],"payload":{"lines":"595,596"}}],"payload":{"lines":"331,332"}},{"content":"Implement knowledge mining and document intelligence solutions (10–15%)","children":[{"content":"Implement an Azure AI Search solution","children":[{"content":"Provision an Azure AI Search resource","children":[{"content":"Azure Cognitive Search (formerly known as “Azure Search”) is a cloud search service that gives<br>\ndevelopers infrastructure, APIs, and tools for building a rich search experience over private,<br>\nheterogeneous content in web, mobile, and enterprise applications.","children":[],"payload":{"lines":"677,680"}},{"content":"On the search service itself, the two primary workloads are indexing and querying.","children":[{"content":"<strong>Indexing</strong> engine","children":[{"content":"Intake process that loads content into your search service and makes it searchable.","children":[],"payload":{"lines":"682,683"}},{"content":"Internally, inbound text is processed into tokens and stored in inverted indexes, and inbound<br>\nvectors are stored in vector indexes.","children":[],"payload":{"lines":"683,685"}},{"content":"The document format that Azure AI Search can index is JSON. You can upload JSON documents<br>\nthat you've assembled, or use an indexer to retrieve and serialize your data into JSON.","children":[],"payload":{"lines":"685,687"}},{"content":"Applied AI through a <strong>skillset</strong> extends indexing with image and language models.","children":[{"content":"If you have images or large unstructured text in source document, you can attach skills<br>\nthat perform OCR, describe images, infer structure, translate text and more.","children":[],"payload":{"lines":"688,690"}},{"content":"You can also attach skills that perform data chunking and vectorization.","children":[],"payload":{"lines":"690,691"}}],"payload":{"lines":"687,691"}}],"payload":{"lines":"681,691"}},{"content":"<strong>Query engine</strong> is used when your client app sends query requests to a search service<br>\nand handles responses. All query execution is over a search index that you control.","children":[{"content":"<strong>Semantic ranking</strong> is an extension of query execution. It adds secondary ranking,<br>\nusing language understanding to reevaluate a result set, promoting the most semantically<br>\nrelevant results to the top.","children":[],"payload":{"lines":"693,697"}}],"payload":{"lines":"691,697"}}],"payload":{"lines":"680,697"}}],"payload":{"lines":"675,676"}},{"content":"Create data sources","children":[{"content":"Azure AI Search can index content from a variety of data sources:","children":[{"content":"Azure Storage (Blobs, Tables)","children":[],"payload":{"lines":"700,701"}},{"content":"Azure Cosmos DB","children":[],"payload":{"lines":"701,702"}},{"content":"Azure SQL Database, managed instance or SQL server","children":[],"payload":{"lines":"702,703"}}],"payload":{"lines":"699,703"}},{"content":"Both <em>push</em> and <em>pull</em> methods are supported.","children":[],"payload":{"lines":"703,705"}}],"payload":{"lines":"697,698"}},{"content":"Create an index","children":[{"content":"An <strong>index</strong> is a collection of JSON objects with unique keys and one or more fields.","children":[],"payload":{"lines":"707,708"}},{"content":"Index attributes can be:","children":[{"content":"Searchable: Full-text search","children":[],"payload":{"lines":"709,710"}},{"content":"Filterable","children":[],"payload":{"lines":"710,711"}},{"content":"Facetable: Used for aggregations/categorization and hit count","children":[],"payload":{"lines":"711,712"}},{"content":"Sortable","children":[],"payload":{"lines":"712,713"}},{"content":"Retrievable: Enables the field to be returned in search results or hidden from them.","children":[],"payload":{"lines":"713,715"}}],"payload":{"lines":"708,715"}}],"payload":{"lines":"705,706"}},{"content":"Define a skillset","children":[{"content":"A <strong>skillset</strong> is a reusable object in Azure AI Search that's attached to an indexer.","children":[{"content":"Contains one or more skills that call built-in AI or external custom processing over documents<br>\nretrieved from an external data source.","children":[],"payload":{"lines":"718,720"}}],"payload":{"lines":"717,720"}},{"content":"Steps:","children":[{"content":"Document Cracking","children":[],"payload":{"lines":"721,722"}},{"content":"Field mappings","children":[],"payload":{"lines":"722,723"}},{"content":"Skillset execution","children":[],"payload":{"lines":"723,724"}},{"content":"Output field mappings","children":[],"payload":{"lines":"724,725"}},{"content":"Push to index","children":[],"payload":{"lines":"725,726"}}],"payload":{"lines":"720,726"}},{"content":"Up to 30 skills per skillset","children":[],"payload":{"lines":"726,727"}},{"content":"Can repeat skills","children":[],"payload":{"lines":"727,728"}},{"content":"Support chained operations, looping and branching","children":[],"payload":{"lines":"728,730"}}],"payload":{"lines":"715,716"}},{"content":"Implement custom skills and include them in a skillset","children":[{"content":"An AI enrichment pipeline can include both built-in skills and custom skills that you personally<br>\ncreate and publish.","children":[],"payload":{"lines":"732,734"}},{"content":"Your custom code executes externally from the search service (for example, as an Azure function),<br>\nbut accepts inputs and sends outputs to the skillset just like any other skill.","children":[],"payload":{"lines":"734,736"}},{"content":"Following data are required to setup a new custom skill in a skillset:","children":[{"content":"<code>uri</code>","children":[],"payload":{"lines":"737,738"}},{"content":"<code>httpMethod</code> (PUT or POST)","children":[],"payload":{"lines":"738,739"}},{"content":"<code>httpHeaders</code>","children":[],"payload":{"lines":"739,740"}},{"content":"<code>timeout</code> (default 30s)","children":[],"payload":{"lines":"740,741"}},{"content":"<code>batchSize</code>: data records to send to the skill at once (1000 per default)","children":[],"payload":{"lines":"741,742"}},{"content":"<code>degreeOfParallelism</code>: maximum number of concurrent requests for this endpoint<br>\n(between 1 and 10, default 5)","children":[],"payload":{"lines":"742,744"}},{"content":"For managed-identity connections:","children":[{"content":"<code>resourceId</code>","children":[],"payload":{"lines":"745,746"}},{"content":"<code>authResourceId</code>","children":[],"payload":{"lines":"746,748"}}],"payload":{"lines":"744,748"}}],"payload":{"lines":"736,748"}}],"payload":{"lines":"730,731"}},{"content":"Create and run an indexer","children":[{"content":"An indexer definition consists of properties that uniquely identify the <strong>indexer</strong>,<br>\nspecify which <strong>data source</strong> and <strong>index</strong> to use, and provide other configuration options<br>\nthat influence run time behaviors, including whether the indexer runs on demand or on a schedule.","children":[],"payload":{"lines":"750,753"}},{"content":"Extracts and serializes data from a data source, passing it to a search service for data ingestion.","children":[],"payload":{"lines":"753,755"}}],"payload":{"lines":"748,749"}},{"content":"Query an index, including syntax, sorting, filtering, and wildcards","children":[{"content":"<strong>Full text search semantics</strong> based on <em>Lucene</em> query syntax over the index.","children":[{"content":"<a href=\"https://lucene.apache.org/core/6_6_1/queryparser/org/apache/lucene/queryparser/simple/SimpleQueryParser.html\">Simple Lucene Query Parser</a>","children":[],"payload":{"lines":"758,759"}},{"content":"<a href=\"https://lucene.apache.org/core/6_6_1/queryparser/org/apache/lucene/queryparser/classic/package-summary.html\">Full Lucene Query Syntax</a>: for specialized query forms: wildcard, fuzzy search, proximity search, regular expressions.","children":[],"payload":{"lines":"759,760"}}],"payload":{"lines":"757,760"}},{"content":"Queries are processed in 4 stages:","children":[{"content":"Query parsing","children":[],"payload":{"lines":"761,762"}},{"content":"Lexical analysis","children":[],"payload":{"lines":"762,763"}},{"content":"Document retrieval","children":[],"payload":{"lines":"763,764"}},{"content":"Scoring","children":[],"payload":{"lines":"764,766"}}],"payload":{"lines":"760,766"}}],"payload":{"lines":"755,756"}},{"content":"Manage Knowledge Store projections, including file, object, and table projections","children":[{"content":"Projection is a way to define the shape of the data that you want to retrieve from the index.","children":[{"content":"Enriched documents are stored in the knowledge store.","children":[],"payload":{"lines":"769,770"}},{"content":"Useful for knowledge mining scenarios.","children":[],"payload":{"lines":"770,771"}},{"content":"Projections can be read from 3 types of sources:","children":[{"content":"Files","children":[],"payload":{"lines":"772,773"}},{"content":"Objects","children":[],"payload":{"lines":"773,774"}},{"content":"Tables","children":[],"payload":{"lines":"774,776"}}],"payload":{"lines":"771,776"}}],"payload":{"lines":"768,776"}}],"payload":{"lines":"766,767"}}],"payload":{"lines":"673,674"}},{"content":"Implement an Azure AI Document Intelligence solution","children":[{"content":"Provision a Document Intelligence resource","children":[{"content":"Azure AI Document Intelligence is a cloud service that uses machine learning to extract<br>\ninformation from documents.","children":[],"payload":{"lines":"780,783"}}],"payload":{"lines":"778,779"}},{"content":"Use prebuilt models to extract data from documents","children":[{"content":"Prebuilt models are trained on a wide range of document types and can extract information<br>\nfrom documents with minimal configuration:","children":[{"content":"Receipts","children":[],"payload":{"lines":"787,788"}},{"content":"Invoices","children":[],"payload":{"lines":"788,789"}},{"content":"Business cards","children":[],"payload":{"lines":"789,790"}},{"content":"Identity documents","children":[],"payload":{"lines":"790,791"}},{"content":"Contracts","children":[],"payload":{"lines":"791,792"}},{"content":"Tax forms","children":[],"payload":{"lines":"792,793"}},{"content":"Vaccination cards","children":[],"payload":{"lines":"793,794"}},{"content":"and more...","children":[],"payload":{"lines":"794,796"}}],"payload":{"lines":"785,796"}}],"payload":{"lines":"783,784"}},{"content":"Implement a custom document intelligence model","children":[{"content":"You can train custom models to classify and extract information from documents that are specific<br>\nto your organization.","children":[{"content":"<strong>Custom extraction models</strong> can be trained to extract information from documents that are specific<br>\nto your organization.","children":[],"payload":{"lines":"800,802"}},{"content":"<strong>Custom classification models</strong> can be trained to classify documents based on their content.","children":[],"payload":{"lines":"802,803"}}],"payload":{"lines":"798,803"}},{"content":"Train, test, and publish a custom document intelligence model:","children":[{"content":"Create a new project in Document Intelligence Studio","children":[],"payload":{"lines":"804,805"}},{"content":"Label data","children":[],"payload":{"lines":"805,806"}},{"content":"Train the model","children":[],"payload":{"lines":"806,807"}},{"content":"Test the model","children":[],"payload":{"lines":"807,809"}}],"payload":{"lines":"803,809"}}],"payload":{"lines":"796,797"}},{"content":"Create a composed document intelligence model","children":[{"content":"<mark>TODO</mark>","children":[],"payload":{"lines":"811,813"}}],"payload":{"lines":"809,810"}},{"content":"Implement a document intelligence model as a custom Azure AI Search skill","children":[{"content":"<mark>TODO</mark>","children":[],"payload":{"lines":"815,817"}}],"payload":{"lines":"813,814"}}],"payload":{"lines":"776,777"}}],"payload":{"lines":"671,672"}},{"content":"Implement generative AI solutions (10–15%)","children":[{"content":"Use Azure OpenAI Service to generate content","children":[{"content":"Provision an Azure OpenAI Service resource","children":[{"content":"Create an Azure OpenAI resource to access the OpenAI API and use it to generate content:","children":[{"content":"Identify subscription, resource group, region, and pricing tier","children":[],"payload":{"lines":"824,825"}},{"content":"Configure network security","children":[],"payload":{"lines":"825,826"}},{"content":"Confirm configuration to deploy the resource","children":[],"payload":{"lines":"826,827"}}],"payload":{"lines":"823,827"}},{"content":"By CLI:","children":[{"content":"\n<pre><code class=\"language-bash\">az cognitiveservices account create -n &lt;resource-name&gt; -g &lt;resource-group&gt; \\n\n--subscription &lt;subscription-id&gt; --location &lt;location&gt; --kind OpenAI --sku &lt;sku&gt;\n</code></pre>","children":[],"payload":{"lines":"828,833"}}],"payload":{"lines":"827,833"}}],"payload":{"lines":"821,822"}},{"content":"Select and deploy an Azure OpenAI model","children":[{"content":"Azure OpenAI provides access to a range of models that can be used to generate content:","children":[{"content":"GPT-4: Newest model for natural language and code generation","children":[],"payload":{"lines":"836,837"}},{"content":"GPT-3.5: Natural language and code generation","children":[],"payload":{"lines":"837,838"}},{"content":"DALL-E: Image generation","children":[],"payload":{"lines":"838,839"}},{"content":"Embeddings: Similarity, text and code search etc.","children":[],"payload":{"lines":"839,840"}}],"payload":{"lines":"835,840"}},{"content":"Deploy a model:","children":[{"content":"Select subscription and OpenAI resource","children":[],"payload":{"lines":"841,842"}},{"content":"Create a new deployment:","children":[{"content":"Select the model","children":[],"payload":{"lines":"843,844"}},{"content":"Add a deployment name","children":[],"payload":{"lines":"844,845"}},{"content":"Setting advanced features like content filtering, token rate limits, etc.","children":[],"payload":{"lines":"845,846"}}],"payload":{"lines":"842,846"}}],"payload":{"lines":"840,846"}},{"content":"By CLI:","children":[{"content":"\n<pre><code class=\"language-bash\">az cognitiveservices account deployment create -n &lt;model-name&gt; -g &lt;resource-group&gt; \\n\n--deployment-name &lt;deployment-name&gt; --model-name &lt;model-name&gt; \\n\n--model-version &lt;model-version&gt; --model-format <span class=\"hljs-string\">\"OpenAI\"</span> \\n\n--scale-settings-scale-type <span class=\"hljs-string\">\"Standard\"</span>\n</code></pre>","children":[],"payload":{"lines":"847,854"}}],"payload":{"lines":"846,854"}}],"payload":{"lines":"833,834"}},{"content":"Submit prompts to generate natural language","children":[{"content":"You can submit prompt for multiple purposes:","children":[{"content":"Classifying content","children":[],"payload":{"lines":"857,858"}},{"content":"Generating new content","children":[],"payload":{"lines":"858,859"}},{"content":"Transformation and translation","children":[],"payload":{"lines":"859,860"}},{"content":"Summarization","children":[],"payload":{"lines":"860,861"}},{"content":"Continuation","children":[],"payload":{"lines":"861,862"}},{"content":"Question answering","children":[],"payload":{"lines":"862,863"}},{"content":"Chat","children":[],"payload":{"lines":"863,864"}},{"content":"and more...","children":[],"payload":{"lines":"864,866"}}],"payload":{"lines":"856,866"}}],"payload":{"lines":"854,855"}},{"content":"Submit prompts to generate code","children":[{"content":"Use prompt engineering to define precisly the code you want to generate:","children":[{"content":"Define the problem","children":[],"payload":{"lines":"869,870"}},{"content":"Define the input","children":[],"payload":{"lines":"870,871"}},{"content":"Define the output","children":[],"payload":{"lines":"871,872"}},{"content":"Define the constraints","children":[],"payload":{"lines":"872,873"}},{"content":"Define the evaluation metric","children":[],"payload":{"lines":"873,874"}}],"payload":{"lines":"868,874"}},{"content":"Break down complex problems into smaller, more manageable parts","children":[],"payload":{"lines":"874,876"}}],"payload":{"lines":"866,867"}},{"content":"Use the DALL-E model to generate images","children":[{"content":"DALL-E is a model that can generate images from textual descriptions:","children":[{"content":"Uses Neural network based model","children":[],"payload":{"lines":"879,880"}},{"content":"Uses Natural Language Processing (NLP) to understand the textual description","children":[],"payload":{"lines":"880,881"}},{"content":"Specify style and content to generate images with specific characteristics","children":[],"payload":{"lines":"881,883"}}],"payload":{"lines":"878,883"}}],"payload":{"lines":"876,877"}},{"content":"Use Azure OpenAI APIs to submit prompts and receive responses","children":[{"content":"<mark>TODO</mark>","children":[],"payload":{"lines":"885,887"}}],"payload":{"lines":"883,884"}}],"payload":{"lines":"819,820"}},{"content":"Optimize generative AI","children":[{"content":"Configure parameters to control generative behavior","children":[{"content":"Use <mark><a href=\"https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cpython-new&amp;pivots=programming-language-studio#playground\">Chat Playground</a></mark> to familiarize with model parameters to control the generative behavior, like:","children":[{"content":"<strong>Deployments</strong>: Your deployment name that is associated with a specific model.","children":[],"payload":{"lines":"892,893"}},{"content":"<strong>Temperature</strong>: Controls randomness.","children":[{"content":"Lowering the temperature means that the model produces more repetitive and deterministic responses.","children":[],"payload":{"lines":"894,895"}},{"content":"Increasing the temperature results in more unexpected or creative responses.","children":[],"payload":{"lines":"895,896"}},{"content":"Try adjusting <em>temperature</em> or <em>Top P</em> but not both.","children":[],"payload":{"lines":"896,897"}}],"payload":{"lines":"893,897"}},{"content":"<strong>Max length (tokens)</strong>: Set a limit on the number of tokens per model response.","children":[{"content":"The API supports a maximum of 4096 tokens shared between the prompt (including system message,<br>\nexamples, message history, and user query) and the model's response. One token is roughly four<br>\ncharacters for typical English text.","children":[],"payload":{"lines":"898,901"}}],"payload":{"lines":"897,901"}},{"content":"<strong>Top probabilities</strong> Similar to temperature, this controls randomness but uses a different<br>\nmethod. Lowering Top P narrows the model's token selection to likelier tokens.<br>\nIncreasing Top P lets the model choose from tokens with both high and low likelihood.","children":[{"content":"Try adjusting <em>temperature</em> or <em>Top P</em> but not both.","children":[],"payload":{"lines":"904,905"}}],"payload":{"lines":"901,905"}},{"content":"<strong>Multi-turn conversations</strong> Select the number of past messages to include in each new API<br>\nrequest. This helps give the model context for new user queries. Setting this number to<br>\n10 results in five user queries and five system responses.","children":[],"payload":{"lines":"905,908"}},{"content":"<strong>Stop sequences</strong> \tStop sequence make the model end its response at a desired point.<br>\nThe model response ends before the specified sequence, so it won't contain the stop sequence<br>\ntext. For GPT-35-Turbo, using &lt;|im_end|&gt; ensures that the model response doesn't generate a<br>\nfollow-up user query. You can include as many as four stop sequences.","children":[],"payload":{"lines":"908,913"}}],"payload":{"lines":"891,913"}}],"payload":{"lines":"889,890"}},{"content":"Apply prompt engineering techniques to improve responses","children":[{"content":"To improve generative AI responses, prompt engineering techniques can be used:","children":[{"content":"Provide clear instructions","children":[],"payload":{"lines":"916,917"}},{"content":"Primary, supporting, and grounding content","children":[],"payload":{"lines":"917,918"}},{"content":"Providing cues","children":[],"payload":{"lines":"918,919"}},{"content":"Requesting output composition: length, style, formatting, etc.","children":[],"payload":{"lines":"919,920"}},{"content":"Using system messages","children":[],"payload":{"lines":"920,921"}},{"content":"Conversation history and few-shot learning","children":[],"payload":{"lines":"921,922"}},{"content":"Chain of thought","children":[],"payload":{"lines":"922,924"}}],"payload":{"lines":"915,924"}}],"payload":{"lines":"913,914"}},{"content":"Use your own data with an Azure OpenAI model","children":[{"content":"You can use your own data with Azure OpenAI models to generate content that is specific to your<br>\norganization:","children":[{"content":"Setup a data-source: such as blob storage","children":[],"payload":{"lines":"928,929"}},{"content":"Configure studio to connect to the data-source","children":[],"payload":{"lines":"929,930"}},{"content":"Use Azure OpenAI model per usual to generate content","children":[],"payload":{"lines":"930,931"}}],"payload":{"lines":"926,931"}},{"content":"You can configure the model with specific parameters to control the generative behavior:","children":[{"content":"<strong>Strictness determines</strong> the system's aggressiveness in filtering search documents based on<br>\ntheir similarity scores.","children":[],"payload":{"lines":"932,934"}},{"content":"<strong>Retrieved documents</strong> is an integer that can be set to 3, 5, 10, or 20, and controls the<br>\nnumber of document chunks provided to the large language model for formulating the final response.","children":[],"payload":{"lines":"934,936"}},{"content":"<strong>Limit responses</strong> attempts to only rely on your documents for responses.","children":[],"payload":{"lines":"936,938"}}],"payload":{"lines":"931,938"}}],"payload":{"lines":"924,925"}},{"content":"Fine-tune an Azure OpenAI model","children":[{"content":"Fine-tuning an Azure OpenAI model allows you to customize the model to better suit your needs","children":[],"payload":{"lines":"940,941"}},{"content":"Fine-tuning is expensive and time-consuming, but reduces the need for many examples to<br>\nachieve good performance","children":[],"payload":{"lines":"941,943"}}],"payload":{"lines":"938,939"}}],"payload":{"lines":"887,888"}}],"payload":{"lines":"817,818"}}],"payload":{"lines":"10,11"}}]},{"colorFreezeLevel":4})</script>
</body>
</html>
